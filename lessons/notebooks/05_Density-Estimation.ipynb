{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Density Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preliminaries\n",
    "\n",
    "- Goal \n",
    "  - Simple maximum likelihood estimates for Gaussian and categorical distributions\n",
    "- Materials        \n",
    "  - Mandatory\n",
    "    - These lecture notes\n",
    "  - Optional\n",
    "    - Bishop pp. 67-70, 74-76, 93-94      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why Density Estimation?\n",
    "\n",
    "Density estimation relates to building a model $p(x|\\theta)$ from observations $D=\\{x_1,\\dotsc,x_N\\}$. \n",
    "\n",
    "Why is this interesting? Some examples:\n",
    "\n",
    "- **Outlier detection**. Suppose $D=\\{x_n\\}$ are benign mammogram images. Build $p(x | \\theta)$ from $D$. Then low value for $p(x^\\prime | \\theta)$ indicates that $x^\\prime$ is a risky mammogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Compression**. Code a new data item based on **entropy**, which is a functional of $p(x|\\theta)$: \n",
    "$$\n",
    "H[p] = -\\sum_x p(x | \\theta)\\log p(x |\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Classification**. Let $p(x | \\theta_1)$ be a model of attributes $x$ for credit-card holders that paid on time and $p(x | \\theta_2)$ for clients that defaulted on payments. Then, assign a potential new client $x^\\prime$ to either class based on the relative probability of $p(x^\\prime | \\theta_1)$ vs. $p(x^\\prime|\\theta_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Example Problem\n",
    "\n",
    "<span class=\"exercise\">\n",
    "Consider a set of observations $D=\\{x_1,…,x_N\\}$ in the 2-dimensional plane (see Figure). All observations were generated by the same process. We now draw an extra observation $x_\\bullet = (a,b)$ from the same data generating process. What is the probability that $x_\\bullet$ lies within the shaded rectangle $S$?\n",
    "</span>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAG2CAYAAAB20iz+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3X+Q1PV9x/HX3cIuINwpoAbDIURLMCU6Ck6LRYFDrQzlh03M0FpjWuxEBolIplVM7m69xYERKUkjUlAH/6khTZUIcw2FAfnV1ApUJsRfVJQ5IpiIxj0B3Q173/5Bvuve3nf3dvf73e+vfT5mbuLu7e2+7yvx++LzeX8+nzrDMAwBAACEUL3XBQAAAFQLQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIRWYIPO8uXLVVdXp8WLF3tdCgAA8KlABp39+/dr/fr1uvrqq70uBQAA+Fjggs7p06d155136qmnntJFF13kdTkAAMDH+nldQLkWLlyomTNn6uabb9ayZcuKvjaVSimVSmUfd3d366OPPtKwYcNUV1dX7VIBAIADDMPQJ598ossuu0z19eWN0QQq6GzcuFH/+7//q/3795f0+uXLl+uRRx6pclUAAMANx48f18iRI8v6mcAEnePHj+v+++/Xtm3bNGDAgJJ+ZunSpVqyZEn2cTKZ1KhRo3T8+HE1NDRUq1QAAOCgrq4uNTU1aciQIWX/bJ1hGEYVanLcz372M91+++2KRCLZ5zKZjOrq6lRfX69UKtXje1a6urrU2NioZDJJ0AEAICDs3L8DM6Izffp0HT58uMdzf/u3f6tx48bpwQcf7DPkAACA2hOYoDNkyBCNHz++x3MXXHCBhg0b1ut5AAAAKYDLywEAAEoVmBEdK7t27fK6BAAA4GOM6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAgNAi6AAAKhaPx5VIJCy/l0gkFI/H3S0IyEPQAQBULBKJqLW1tVfYSSQSam1tVSQS8agy4Lx+XhcAAAiulpYWSVJra2v2sRly2tvbs98HvFJnGIbhdRFu6erqUmNjo5LJpBoaGrwuBwBCwww30WhU6XSakANH2bl/E3QAAI6IxWJKp9OKRqNKpVJel4MQsXP/pkcHAGBbIpHIhpx0Ol2wQRlwG0EHAGBLbk9OKpVSe3u7ZYMy4AWakQEAFbNqPLZqUAa8QtABAFQsk8lYNh6bjzOZjBdlAVk0IwMAAF+jGRkAAMACQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcA4Kh4PK5EImH5vUQioXg87m5BqGkEHQCAoyKRiFpbW3uFnUQiodbWVkUiEY8qQy3q53UBAIBwaWlpkSS1trZmH5shp729Pft9wA11hmEYXhfhlq6uLjU2NiqZTKqhocHrcgAg1MxwE41GlU6nCTmomJ37N0EHAFA1sVhM6XRa0WhUqVTK63IQUHbu3/ToAACqIpFIZENOOp0u2KAMVBNBBwDguNyenFQqpfb2dssGZaDaaEYGADjKqvHYqkEZcANBBwDgqEwmY9l4bD7OZDJelIUaRTMyAADwNZqRAQAALAQm6Kxdu1ZXX321Ghoa1NDQoEmTJunnP/+512UBAAAfC0zQGTlypFasWKEDBw7owIEDam5u1pw5c/Taa695XRoAAPCpQPfoDB06VCtXrtT8+fNLej09OgAABI+d+3cgV11lMhn99Kc/1ZkzZzRp0qSCr0ulUj124uzq6nKjPAAA4BOBmbqSpMOHD2vw4MGKxWK69957tWnTJn3lK18p+Prly5ersbEx+9XU1ORitQAAwGuBmrpKp9Pq7OzUxx9/rOeff15PP/20du/eXTDsWI3oNDU1MXUFAECA1OyhnjfffLOuuOIKrVu3rqTX06MDAEDw1Ow+OoZhcBouAAAoKDDNyA8//LBmzJihpqYmffLJJ9q4caN27dqlrVu3el0aAADwqcAEnd/85je66667dPLkSTU2Nurqq6/W1q1bdcstt3hdGgAA8KnABJ1nnnnG6xIAAEDABLpHBwAAoBiCDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACC2CDgAACK1+XhcAAChTJiPt3SudPCmNGCHdeKMUiXhdFeBLBB0ACJIXXpDuv1/69a8/f27kSOmHP5T+8i+9qwvwKaauACAoXnhB+vrXe4YcSXrvvfPPv/CCN3UBPkbQAYAgyGTOj+QYRu/vmc8tXnz+dQCyCDoAEAR79/YeycllGNLx4+dfByCLoAMAPhSPx5VIJD5/4uTJ7D8mJMUL/WDO6wAQdADAlyKRiFpbWz8POyNGSDofclolFVxj9YfXATiPVVcA4EMtLS2SpNbW1vOPH35YiYYGtXZ1qV1SS/4P1NWdX311442u1gn4HUEHAHwqN+wsW7ZM6XT6fMipq+vZlFxXd/5/f/AD9tMB8jB1BQAu6dV3kyORSCgej/d6vqWlRdFoVOl0WtFoVC3PPy998Ys9XzRypPTv/84+OoAFgg4AuKRX380fJBIJtba2KmIxGpNIJLIhJ51OK/Haa9KxY9JLL0nPPXf+f999l5ADFMDUFQC4pFffTUtLNuS0t7dnv2/K/575OPe9ABRH0AEAF1n23ZQQcvJ/NvcxgMIIOgDgspaWlmzIiUajloElk8n0CDnxeFyRSCT7OJOzA3IikVAmk7Hs8QFqHUEHAFzWq+8mkegVdvJDi9nfI/Ucyckd+QHQG0EHAFxUad9Nuf09AM4j6ACAS+z23ZTa3wPgc3WGYXUUbjh1dXWpsbFRyWRSDQ0NXpcDwGP5fS+5qtH34tTnxWKx7NRXKpVyrD7Ar+zcvxnRAVCz3O57KRZiSh2VKaW/B8DnCDoAalbQ+l7YVwcoH0EHQE0LSt8L++oAlaFHBwDk/74Xt/uJAD+xc/8m6ACoeeZoidn34scRHaCW2bl/c6gngJqWOyWUSqXU3t5uefAmgGCiRwdAzaLvBQi/wIzoLF++XNdff72GDBmiSy65RHPnztVbb73ldVkAAiz/PClTS0uL2tvbe5wnBSCYAtOjc9ttt2nevHm6/vrrde7cOX3ve9/T4cOH9frrr+uCCy4o6T3o0QGCIeiNt0GvH/CbmujR2bp1q771rW/pj//4j3XNNddow4YN6uzs1MGDB70uDYDDzI388vtkzKmmSCTiUWWlCXr9QJgEtkcnmUxKkoYOHVrwNalUqscy0a6urqrXBcC+SjfySyaT+v3vf+9anYUsWLBAZ8+eVWtrq86ePavvfve7WrVqlVasWKGHHnpICxYs0KlTp7wuEy7o37+/GhsbvS6jpgVm6iqXYRiaM2eOfve732nv3r0FXxePx/XII4/0ep6pKyAYyln2nUwmtW7duuxfgvxg37592rNnjyKRiDKZjG666SZNnjzZ67LgosbGRn37298m7NhUc/voLFy4UB0dHdq3b59GjhxZ8HVWIzpNTU0EHSBASt3I79SpU1q9erUGDhyoQYMGuVhhcf/4j/+oTCajSCSixx57zOty4KKzZ8/q008/1QMPPKDhw4f3+N7//M//aMWKFTp48KB+85vf6MILL9SXvvQl3XDDDVq1apVHFftXTR3quWjRIm3evFl79uwpGnKk8/+BjMViLlUGwGmVHGA5aNAgDR482KUKi+vo6FAmk1G/fv107tw57d69WzNnzvS6LLjo008/7fVcR0eHZs+eralTp+qxxx7TiBEjdPLkSR04cEAbN24k6DgsMEHHMAwtWrRImzZt0q5duzRmzBivSwJQRUE/wLKjo0ObN2/W7NmzNXPmzOxjSYSdGvfYY49pzJgx+s///E/16/f5bXjevHmM+lVBYILOwoUL9dxzz+nFF1/UkCFD9P7770s6P/85cOBAj6sD4KSgb+SXH3Kkz8MNYQcffvihhg8f3iPkmOrrA7MYOjACE3TWrl0rSZo6dWqP5zds2KBvfetb7hcEoGqKbeRnft/Puru7e4Qck/m4u7vbi7LgE5MmTdLTTz+t73znO7rzzjt13XXXqX///l6XFVqBbEauFBsGAuFlNiMPGzbMNz06qG2nT5/Whx9+2KsZ+cMPP9TcuXO1b98+SeeXoF9//fWaNWuW7rvvPv78WqiJDQMBeC8ejxc87DKRSLDbr01btmxRR0eH5fc6Ojq0ZcsWlytCNQwbNkx79+7V/v37tWLFCs2ZM0dHjhzR0qVL9dWvfpU9lhxG0AFQMnb8ra76+npt3ry5V9gxe37o3wiXiRMn6sEHH9RPf/pTnThxQg888ICOHTtGQ7LDAtOjA/hBrZ9hVOmOxSiNVcOyVWMzwqd///5qa2vT6tWr9atf/crrckKFoAOUwRzRkHqu+sm92YddbthZtmxZnzsW+82WLVtUX19vGRo6OjrU3d2tWbNmeVDZeblh5z/+4z907tw5Qk7InDx5UiNGjOj1/BtvvCFJuuyyy9wuKdQIOkAZrEY0pk2bpl27dlne7MM6ytPS0pINOdFoNDAhR/p8ekjqucQ7d+TECXYC1cyZM7Mhp1+/flUJOX4PfGH253/+5xo5cqRmzZqlcePGqbu7W4cOHdKqVas0ePBg3X///V6XGCpM+AJlamlpUXt7u1pbWxWLxbRr1y7L14W5b8Vqx+KgmDlzpmbPnt2jF6Ya00N2+m06OjqyIefcuXMFG5S9qg/2fP/739dFF12k1atXa/bs2ZoxY4b++Z//WTfffLNeeeUVffWrX/W6xFBhRAeoQP6Ixve///2a6VsJ+o7FkjvTQ5X227i1ozL9QN75xje+oW984xtel1EzCDpABfJHNCRlR3mC2LdSqqDvWJzLjemhcgOV2zsq0w+EWsDYJFCm3Jt9KpXKBhxJ2eATtL6VUhXbsbi9vd33OxbncmN6SDofJszP6CtQFdtRefbs2VXZUbmc+oAgYkQHKEMpIxrlnLQdNMWaqu38rm4v23fzwE2rQFXoM4o1/1YrgJRTHxBEjOgAZSg0omGaOnVqj1GeIDXpesnNjQgLTQ/lNyg7/Vlr1qypymfY2U3ZjfoArzGiA5TBalQhTH0rXnFzI0K3Dtx0q9+m0uXynLCOWsGhnkCFzOmWTCbT43/Nm3T+82HcT8dpZrgxp//KCTl+O9TTzX1qCk3FFWssZh+d6it0qCfKx6GegAfM6RYz3JiPp0+fbvl8GPfTcVpLS0toGrpnzZpVMGTMnDnT0RCRO/W2cOHCkpaIu1kf4CWCDlCh3I0Dzcbj5uZm7dy5U83Nzb2mXzKZTE2e/F3OiedB3ojQa6yeAqwRdAAb8ndJNkPOzp07FYvFevSY1OrJ36X+3oWW7RN2SuPWcnkgaGhGBmzK3yV5x44disVivaZfavXk71J+bxq67XFzuTwQNAQdwKb86Zbp06f3mn6xunmHeQflfH393sU2IjS/D2usngKKY9UVYEP+SMT06dOz01c7duwoOGKTO+KTSqU8/A3cVc3f2y+rrtxezcTqKf9i1ZVzWHUFeMBq+iW3R8ccycnvNanVhtta+b3dPhWc1VNAcQQdoEL50y3m4x07dvQ49yn3HKhabbi1+3uXs3LLa1a7LHMqOOAdenSACuXfXHMfW/Wa1GrDrRO/t7lyK/+1ue/tJ2E4FZwpMYQFQQdwSa023Drxe5eycuvUqVMOV27PzJkzsyEniPvaVHq0BOA3NCMDcI3dU8qLHRHhl2ZkkxkIzH1tgjaiI1V2tAQ+RzOyc2hGBhAIdjdNDMoREWE5FbySoyUAv2HqCoBr7G6aaLVyy29hJ2z72gR9Cg4g6ABwVaWbJhbaTTn3Pf2gu7vbctTDfNzd3e1FWRWzOlqCsIMgIegAcF3+sRnlhhzzPaTPR4cWLFhQ3aJLVGwlUtACAkdLIAwIOgBcV+4UVK2uWPNS2KbgULsIOgBc1dcUlNXKLHMlltXKrNxVV3BO2KbgULsIOgBcU8oUlBebA7I5Xm9hmoJDbSPoAHBNKVNQ5mhNpSuzKhHUzfEIaEDfCDoAXFNsM8DcAFPpyqxKWfWeBGFzvKAGNMBNBB0AFbO703Ex5a7MsiuI51MFNaABbmJnZAAVs7vTcTFWK7OqbebMmdn9YoKyOR67FwPFMaIDoGJ2dzouxO3NAc1eF0m9NseT5PteF3YvBgoj6ACwxel+mlJWZjkddnJ7Xaw2x3Oy16UaDcTsXgwURtABYJuT/TRh3xzwyJEjOnLkiCTrBuKxY8eW9X7sXgwUR9ABYJuTh22WujLLSebmeFLvZmTz+04ZN26cjhw5YtlAbH6/VE7uXsxSdYQVQQcIgGqubrIrKIdtFpN7A692r0tuEMkNVZLKaiLesmWLjhw5UvBnxo4dW1ZAY6k6wopVV0AAVHN1kx2F+mna29st6/U7q16XajBXSkmqKORI54OJOQWWywwm48aNK2sEJnf1lvl7s1QdYcCIDuACuyMy1VrdZFeY+mmC1utSjT10griXENAXgg7gAifOb3J7t+B8lR626UYdpn379mnAgAH62te+VtZ7un1Sd26IMkePKvmccoJJqT04LFVH2DB1BbjAajqnkhGZlpaWbMOvG7sF5/LL9FmhOlatWqU9e/Zk98MpR7GTumfPnu1oM3L+svU1a9b0aIQud7qs1E0OzR6c/Pc36zGvm1vTd4BbGNEBXOLEiIyTq5vK5Zfps0J1rFixQjfddJNuueWWst/TqZO6Sxk1MftqCo0evfnmm2V9Zql76JQy1RW06TugFHWGYRheF+GWrq4uNTY2KplMqqGhwetyUKNisVg2rKRSqZJ/rtDqJrd7dMzPNcOWVz1C+XU89NBDqq+v17BhwzR48GDX65EKN+/mPt/d3e3YMu78z1u1alXBlVjme5sjO2YwKhRy+vqd0LfTp0/rww8/1AMPPKDhw4d7XU6g2bl/M3UFuKjS85v8tLqp0umzeDxesM5EItGjv6eU1+bX8d3vfrfo52/ZsqXgNExHR4e2bNlS0u9RTCkrl8w+mEI/X2nIkT7fgyd/iip3eqrQVJeb03eAmwg6gEtyw0oqlSorpBRb3dTe3u7q6qZKw1o5PT6lvDa/jlWrVhX9/FJ7VOxy65BNq2CSu2z9zTfflGS9msyqB8epAAb4TSTu1S5jHkilUlqxYoWWLl2qWCzmdTkIiHg8rr1792rKlCm9vpdIJPTSSy9p6tSpRd/DakRmypQp2Rt6JBKxfH/T1KlTC35/ypQpfX6+U3J/j+3bt5dcv1ln/usLTb/19VpJvepIJBKqq6vTuHHjFI1Ge33+2LFjs2Gnvr5eY8eOrdq0zNixY7V169ZsoFi8eLFj72368pe/bHlchPl7/uIXv9DWrVv1xhtvWE5PLV68uNf1gLPS6bQ+/fRTTZo0SYMGDfK6nECzc/+mGRnogxNLw8Ow34wTh22W05Bd6LXmc/l1nD17VitWrNCgQYN0++23W36+W/vEeH3IptUScbeX0AN+QTMyUAK/NAJ7ycljKMppyM5/baE6Tp06pa997Wsl7aOzcOHCbAhYs2ZNSTWXqq+VTG4wPzO34djJJmiUhmZk59i5fwdqRGfPnj1auXKlDh48qJMnT2rTpk2aO3eu12WhBni9WZ8fOHXYZjlL5K1eW6yOyZMna9iwYUU/v5qjLX4YNakkaDGSgzALVDPymTNndM011+iJJ57wuhTUIC836wuLUhqyzRVXhV47bdq0ij8/96ZvbtRXySZ9hdhduWR3ZVihoOX07wkEie0RHXPmq66uznYxfZkxY4ZmzJhR9c8BrHi5WV8YlNrjk9sTZTVqtmvXroquvRujLXY3HrR7gnixoGV+H6g1FQedZ555RqtXr9b//d//SZL+6I/+SIsXL9Y999zjWHF2pVKpHvP/XV1dHlaDICvUoyNV70ynsCm1IbulpUU7d+7Url27sq/Jb/wu1rx99uxZy+c/++wz3XbbbZoyZYpOnz6dfX7KlClKp9P67LPPejzvBbOWzZs3K51O65ZbbtH27du1detWy9rzmaNdVq8xV8V5/TvWkkJ/FuGuipqRW1patHr1ai1atEiTJk2SJP33f/+3nnjiCd1///1atmyZ44Xmq6ur67NHJx6P65FHHun1PM3IKEehxuNabEh2U7k7MCeTSa1bt07JZNLFKqtj37592rNnjyKRiDKZjG666SZNnjzZ67JQgcbGRn37299WY2Oj16UEmp1m5IqCzvDhw/WjH/1If/VXf9Xj+R//+MdatGiRTp06Ve5blq2UoGM1otPU1ETQQVmcXG2E8pR7XEYymdTvf/97Fyqrvi9+8YvZ3/29997zuhxUqH///oQcB7i+6iqTyWjixIm9np8wYYLOnTtXyVtWRSwWY2NA2ObUaiOUp5KeqLDcUPJ/97Vr1/JnDahQRauu/uZv/kZr167t9fz69et155132i4K8ItyzmeCc+wclxF0tfy7A9VQ8ojOkiVLsv9cV1enp59+Wtu2bdOf/umfSpJefvllHT9+XN/85jedr/IPTp8+rbfffjv7+N1339WhQ4c0dOhQjRo1qmqfi9rlxK7IYWdnas/qZ81r29zc3KNBWSp9B+agcmL3aQA9lRx0Xn311R6PJ0yYIEk6evSoJOniiy/WxRdfrNdee83B8no6cOBAjz00zPB1991369lnn63a56J2Wd1kaELuyU4YtPrZTCaj5uZm7dy5s8cZXkE6LqNSxVam7dy5Uzt37qRXDCiXUUOSyaQhyUgmk16XgoBpb283JBnRaNSQZLS3t3tdkq+Y18e8LvmPq/WztST/urS1tRnt7e2W16u9vd1oa2vzqFLAeXbu3wQdoERmyIlGo1X7DPPmZcXuzaua722+R6VhkCBZmtxQY/6zVcjhGiJsCDolIuigUm7diAvdpJy4eVXzvU12wqAbQTIM8v8sMhqGWkDQKRFBB5Vwe2qlmp/nxnszolN9uaGw2LWr9ige4BaCTokIOiiXG6MgxT63Gjf+arx32Ht0/BQYrP79FRoN8+rPL+A0gk6JCDool5c3uGpO5Tj53nZupkG5EVvV09bWZjQ3Nxesvxp/NgqFwmLBNQhBEugLQadEBB0EhROjLoVCmvne9fX1jtzw7IRBP42U9CU/IJghp7m5uejrqvX5uc/lNygXCjtMDSKoCDolIuggCJz6G7idGyOs5QeG/BGdal7P/FCYvwLLDIWFaqDZG0FG0CkRQQd+5/RUTv7NkOXI9uUHBq9GS8oZDWNEB0FH0CkRQQd+V42pHPMmF4lECt7k/DZN5FeFAoOfR0vo0UEYEHRKRNBBrfLzjTgoCgUGc/rKj6MlQWn2Bvpi5/5d0enlAIIjkUgonU4rGo0qnU5zCnYFCh22aZ7J1dzc7MuTxoudndXe3h7qc8MAU8mHegIInvwbtPlY4hTsclgFhkQikQ05N954oyT/nTRe7JBPr2sD3ELQAUKq0CiE5J8bcVBYBYZioyXm9wF4r84wDMPrItzS1dWlxsZGJZNJNTQ0eF0OUFXxeFyRSMQyzCQSCWUymaJ/40dPXM/zuA7wgp37NyM6QEgxbeGsSCRiORKWO3JWC7gOCBqCDuAT/E3Z36ym/aymB8OO64DAcXwNmI+xvBx+xlLgYGDzvfO4DnCTnfs3PTqAjxRaJcXflP0lFotll+ynUimvy/EM1wFusXP/Zh8dBFY8Hi+4X0kikQjkNI+5v0lra6tisRghx4fYl+g8rgOCgqCDwDKbIvP/A2uOgkQiEY8qs6elpSV784hGo4QcH8kdYfPjBoFu4TogUByfSPMxenTCJ4zn+FSj96EaZ2jVGnqozuM6wAt27t+sukKg5a4AWbZsmdLpdKCneqq1kzFLgu1jg8DzuA4InCoEL99iRCe8wnBoZbX/ppz/PqNHjy74vs3NzcaUKVNsfR4AOIVDPVHTwtIUWe0DGPMbnY8dOyZJ2rVrV4/XTZ8+XTt37gxsj5OfhLFhHgicKgQv32JEJ3zMUYrm5uYej3N7dug/6Sl39Ku5udmQZIwePdpob2/PPjavp2FwDe2gnwVwhp37N0EHgZUbcvLDjdXzsG50Nq+T+ZUfcriG9oSxYR5wG0GnRASdcMldSZR/8yDk9FbshpsbdPx0Qw7LajF2EQbsIeiUiKATbtxMCutrCiX/yy/XMExTP2FomAe8QtApEUEn/LiZWCs0MpLbo5P72E/XMAxTP4RwwB6CTokIOuHGzaQ8hRqPraaxvBbkf7dhCGqA1wg6JSLohBc3k/JNmTKlYONxc3Nz0X12DMP9/pkgjtaFaeoN8BJBp0QEnXDiZmJfJdfQzese1BGdsDRTA17jCAjUNLakr1w8HlckErG8holEIvu81TXMPX7DfJx/hIUTqnUshhuKbQjo99qB0KhC8PItRnSAnpwYlanmaAujdQAMgxEdABVyYlSmpaUle6BqNBp1dKSC0ToAdtUZhmF4XYRburq61NjYqGQyqYaGBq/LAXzDDDfmeWHlTD3Z+VkAKIWd+zeHegJQS0tLNqiUMyqTO/qTSqWyh4YG9WBVAOHD1BUAyxPg+wo7VlNcVlNhAOAlRnQQevF4vOAIQyKRKLoyxitu1lzpqEyx/plCK7X8IIh/HgDY4HhrtI+x6qr6/LhvSBBX7rhVcxCvjV21+DsDQceGgSUi6FSfX28iQdw52Y2a/RhM3RDEPw9ALSPolIig4w6/3kSCuLtuEGsOCq4tEBx27t8sL0dV+HXJcSwWyzbdplIpr8spSRBrDopKrq25m7TVn2dzN2n6fABnsbwcvlPpcuVqslpZ5HdBrDkoKr22kUjEslnbDPeRSKQa5QJ7VQmsAAATSElEQVSolOPjSz7G1JV7/DYt4NfptGKCWHNQ2L22/LsB3EWPTokIOu7w203Arw3SxQSx5qBw6tr6LcwDYcZZV/ANP24iF8TzkoJYc1A4dW2recYXAOfQjAxH0aiJWuHXhnsgjOzcvwk6AFCm/JHLck98B1AeO/dvpq4AoAx+nJ4FUFjglpc/+eSTGjNmjAYMGKAJEyZo7969XpcE+BJnOlVHUM/4AmpVoEZ0fvKTn2jx4sV68skn9Wd/9mdat26dZsyYoddff12jRo3yujzAV8z9XqSeIwy5IxJW6LMqrtjvzkgO4D+BGtH5p3/6J82fP1/33HOPrrrqKv3gBz9QU1OT1q5d63VpgO9GUMwRhtzN7UrpJWFDPACh4vBS96pJpVJGJBIxXnjhhR7Pf+c73zFuuummkt6DfXRQTX7d+6aS/V78thcSgNpWExsGvvfee4Yk47/+6796PP/oo48aY8eOtfyZzz77zEgmk9mv48ePE3RQVX4NCGbIiUajJf8MG+IB8As7QSdQU1eSVFdX1+OxYRi9njMtX75cjY2N2a+mpiY3SkQNy50uisVivlhyXOmZTn48rwwAyhWYoDN8+HBFIhG9//77PZ7/7W9/q0svvdTyZ5YuXapkMpn9On78uBulosb5KSDk9uSkUqlePTt9/SwHigIIusAEnWg0qgkTJmj79u09nt++fbtuuOEGy5+JxWJqaGjo8YXKeN1o6/Xnl8MvAaHQfi+lhB07AQkAfMX5mbTq2bhxo9G/f3/jmWeeMV5//XVj8eLFxgUXXGAcO3aspJ+nGblyXjfaevn5bW1tBd+/vb3daGtrK1iPlz065dSd/z0v/10DQL6aaEY2rVmzxrj88suNaDRqXHfddcbu3btL/lmCjj1e38S9+vxSb/xhCQiVBiQAqJaaCjp2EHTs83oljlefX0qoISDYw/UDUAhBp0QEHWdUslQ5DJ/vdcgLu7CMiAFwXk0tL4e3vG609fLz/bSaKowq3ckZAIqqQvDyLUZ07KnVHp38z2dEp7pKvc5MdQG1g6mrEhF0Kuf1tILfPt/u53KTLq6U6Umv/0wAcI+d+3egTi+HdzKZjOX0gfk4k8mE9vML7UcjyfJ08FJUerJ4LbCanrS6vlb/DpjqAtBLFYKXbzGig0pUa/TF66k4P6rkmjClCIQfU1clIujAb7hJf87OVJTXKwEBVBerroCAYiXX54pNT7a3txecnixnJV6QjhIB4Ax6dAAPldqPUgvyQ0Y8HlckElFLS0uva5JIJJTJZLK9TmZAMnt0JOu+KXqjgBpUhREm32LqCn5Cj05xfU1lNTc3VzTVxXUHgocenRIRdOAXLI0uTbFQYqdJnN4oIFjs3L/rDMMw3B5F8kpXV5caGxuVTCbV0NDgdTmoYbnTMvnMaRn6Rc4zp5XM6T2nlo7HYrHstGEqlXKgUgDVYuf+TdABCiCM+IfToaRa4QlAddi5f7PqCijAbFzNX6Vj3iQjkUhVP58VQuc5fb5ZbuNxKpXqdb4WgJBxeBrN1+jRQbm8bFylj8f56881BYKJZuQSEXRQCS8bV2t5hVA1QglnjAHBRDNyiejRQaW8bFwNej9Jpb1O9EgBMNGjA1Sg1B4Yp3tEyhX03ZMr7XWKx+MFf9eWlhZCDoCSEHRQs0q5Aec3rk6dOrVg42q1GoS9Dlp2mUc45F43ThkH4BrHJ9J8jB4d5CvWA2PVC2I+V+h5p3tnwtSjwyZ9ACpFM3KJCDqwUugGXKhx1Xz91KlTezyudsjp6/kg4JRxAJWgGblENCOjkHKbjd1oEA5bM27Qm6oBeMfW/dvx2OVjjOjASqVTKoxOlC5MU3AA3Gfn/k0zMmpapbvkBr1B2E1WjcdWDcoAUA39vC4A8EqhG7Aktba29nhc7OfMx4VeH0blTKtlMhnLaSrzcSaTqXq9AGoXQQc1q5IbcKXhKGzMpflSz9839/qYivUR1cK1AuAtgg5qViU3YEYnzrMKd+yNA8CPWHUFoGKspALgBjv3b4IOAFu8PAcMQG3grCsAnmD1GQC/I+gAqEilS/MBwE00IwMoG6vPAAQFQQdA2Vh9BiAoaEYGAAC+RjMygNCIx+MF+3wSiUSgDjIF4D2CDgBfMXddzg87Zl9QJBLxqDIAQUSPDgBfYddlAE6iRweAL7HrMgATOyOXiKADBAu7LgOQaEYGUKYgNPyy6zIAJxB0gBrk94Zfdl0G4BSakYEa5OeGX3ZdBuAkgg5Qo3LDw7Jly3zT8MuuywCcRDMyUONo+AXgdzQjA6gIDb8Awo6gA9QoGn4B1AJ6dIAaRMMvgFpB0AFqEA2/AGoFzcgAAMDXaEaGK4Kwmy4AALkIOiiZ33fTBQAgX2B6dB599FF1dHTo0KFDikaj+vjjj70uqeb4eTddAACsBCbopNNp3XHHHZo0aZKeeeYZr8upWX7dTRcAACuBa0Z+9tlntXjx4opGdGhGdg676QIA3EIzcgGpVEpdXV09vmAfu+kCAIIi1EFn+fLlamxszH41NTV5XVLgFdpNd/r06QVfz2osAIBXPA068XhcdXV1Rb8OHDhQ8fsvXbpUyWQy+3X8+HEHq689hXbTbW5u1s6dO3uFHVZjAQC85mkz8n333ad58+YVfc3o0aMrfv9YLKZYLFbxz6OnQrvp7tixQ9OnT9fOnTuVSCRYjQUA8A2akeEYM9yYvTuEHACAE2qiGbmzs1OHDh1SZ2enMpmMDh06pEOHDun06dNel4Y/aGlpyYacaDRKyAEAeC4wQae1tVXXXnut2tradPr0aV177bW69tprbfXwwFmsxgIA+E1ggs6zzz4rwzB6fU2dOtXr0qDCq7EIOwAALwVmZ2T4V6HVWFLP4yIAAHAbQQe2FVqNZT7OZDJelAUAQPBWXdnBqisAAIKnJlZdAZWIx+MF+4TYtRkAwo+gg1CLRCKWTdHs2gwAtYEeHYSaVVM0uzYDQO2gRwc1gV2bASC47Ny/CTqoGbFYLLuhYSqV8rocAECJaEYG+sCuzQBQmwg6CD12bQaA2kUzMkKNXZsBoLYRdBBq7NoMALWNZmQ4Lh6PKxKJWI6UJBIJZTIZNuoDAJSMZmT4Cpv0AQD8gqkrOI5N+gAAfsHUFaqGTfoAAE5gw8ASEXTcxyZ9AAC76NGBL7FJHwDAawQdVAWb9AEA/IBmZDiOTfoAAH5B0IHj2KQPAOAXNCMDAABfoxkZAADAAkEHAACEFkEHfYrH4wVXSyUSCc6tAgD4FkEHfeLsKgBAULHqCn3i7CoAQFCx6gol4+wqAIAXOOuqRAQd+zi7CgDgNpaXwxWcXQUACBqCDkrC2VUAgCCiGRl94uwqAEBQEXTQJ86uAgAEFc3IAADA12hGBgAAsEDQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoUXQAQAAoRWIoHPs2DHNnz9fY8aM0cCBA3XFFVeora1N6XTa69IAAICP9fO6gFK8+eab6u7u1rp163TllVfqV7/6lf7+7/9eZ86c0eOPP+51eQAAwKfqDMMwvC6iEitXrtTatWv1zjvvlPwzXV1damxsVDKZVENDQxWrAwAATrFz/w7EiI6VZDKpoUOHFn1NKpVSKpXq8TPS+QsGAACCwbxvVzQ2YwTQ22+/bTQ0NBhPPfVU0de1tbUZkvjiiy+++OKLrxB8HT16tOzM4OnUVTwe1yOPPFL0Nfv379fEiROzj0+cOKEpU6ZoypQpevrpp4v+bP6Izscff6zLL79cnZ2damxstFd8Devq6lJTU5OOHz/OFKBNXEvncC2dwXV0DtfSOclkUqNGjdLvfvc7XXjhhWX9rKdTV/fdd5/mzZtX9DWjR4/O/vOJEyc0bdo0TZo0SevXr+/z/WOxmGKxWK/nGxsb+UPngIaGBq6jQ7iWzuFaOoPr6ByupXPq68tfLO5p0Bk+fLiGDx9e0mvfe+89TZs2TRMmTNCGDRsq+mUBAEBtCUQz8okTJzR16lSNGjVKjz/+uD744IPs977whS94WBkAAPCzQASdbdu26e2339bbb7+tkSNH9vheOS1GsVhMbW1tltNZKB3X0TlcS+dwLZ3BdXQO19I5dq5lYPfRAQAA6AuNLgAAILQIOgAAILQIOgAAILQIOgAAILRqNujMnj1bo0aN0oABAzRixAjdddddOnHihNdlBc6xY8c0f/58jRkzRgMHDtQVV1yhtrY2pdNpr0sLnEcffVQ33HCDBg0aVPbOn7XuySef1JgxYzRgwABNmDBBe/fu9bqkQNqzZ49mzZqlyy67THV1dfrZz37mdUmBtHz5cl1//fUaMmSILrnkEs2dO1dvvfWW12UFztq1a3X11VdnN1ycNGmSfv7zn5f9PjUbdKZNm6Z/+7d/01tvvaXnn39eR48e1de//nWvywqcN998U93d3Vq3bp1ee+01rV69Wv/yL/+ihx9+2OvSAiedTuuOO+7QggULvC4lUH7yk59o8eLF+t73vqdXX31VN954o2bMmKHOzk6vSwucM2fO6JprrtETTzzhdSmBtnv3bi1cuFAvv/yytm/frnPnzunWW2/VmTNnvC4tUEaOHKkVK1bowIEDOnDggJqbmzVnzhy99tprZb0Py8v/YPPmzZo7d65SqZT69+/vdTmBtnLlSq1du1bvvPOO16UE0rPPPqvFixfr448/9rqUQPiTP/kTXXfddVq7dm32uauuukpz587V8uXLPaws2Orq6rRp0ybNnTvX61IC74MPPtAll1yi3bt366abbvK6nEAbOnSoVq5cqfnz55f8MzU7opPro48+0r/+67/qhhtuIOQ4IJlMaujQoV6XgRqQTqd18OBB3XrrrT2ev/XWW/WLX/zCo6qAnpLJpCTx30UbMpmMNm7cqDNnzmjSpEll/WxNB50HH3xQF1xwgYYNG6bOzk69+OKLXpcUeEePHtWPfvQj3XvvvV6Xghpw6tQpZTIZXXrppT2ev/TSS/X+++97VBXwOcMwtGTJEk2ePFnjx4/3upzAOXz4sAYPHqxYLKZ7771XmzZt0le+8pWy3iNUQScej6uurq7o14EDB7Kv/4d/+Ae9+uqr2rZtmyKRiL75zW+WdaREmJV7LaXzZ5LddtttuuOOO3TPPfd4VLm/VHIdUb66uroejw3D6PUc4IX77rtPv/zlL/XjH//Y61IC6ctf/rIOHTqkl19+WQsWLNDdd9+t119/vaz3CMRZV6W67777NG/evKKvGT16dPafzdPTx44dq6uuukpNTU16+eWXyx4WC6Nyr+WJEyc0bdo0TZo0SevXr69ydcFR7nVEeYYPH65IJNJr9Oa3v/1tr1EewG2LFi3S5s2btWfPnl7nNKI00WhUV155pSRp4sSJ2r9/v374wx9q3bp1Jb9HqIKOGVwqYY7kpFIpJ0sKrHKu5Xvvvadp06ZpwoQJ2rBhg+rrQzVQaIudP5PoWzQa1YQJE7R9+3bdfvvt2ee3b9+uOXPmeFgZaplhGFq0aJE2bdqkXbt2acyYMV6XFBqGYZR9nw5V0CnVK6+8oldeeUWTJ0/WRRddpHfeeUetra264oorGM0p04kTJzR16lSNGjVKjz/+uD744IPs977whS94WFnwdHZ26qOPPlJnZ6cymYwOHTokSbryyis1ePBgj6vzryVLluiuu+7SxIkTsyOKnZ2d9IlV4PTp03r77bezj999910dOnRIQ4cO1ahRozysLFgWLlyo5557Ti+++KKGDBmSHXFsbGzUwIEDPa4uOB5++GHNmDFDTU1N+uSTT7Rx40bt2rVLW7duLe+NjBr0y1/+0pg2bZoxdOhQIxaLGaNHjzbuvfde49e//rXXpQXOhg0bDEmWXyjP3XffbXkdX3rpJa9L8701a9YYl19+uRGNRo3rrrvO2L17t9clBdJLL71k+Wfw7rvv9rq0QCn038QNGzZ4XVqg/N3f/V32/9cXX3yxMX36dGPbtm1lvw/76AAAgNCimQIAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQdAoG3dulWTJ0/WhRdeqGHDhukv/uIvdPToUa/LAuATBB0AgXbmzBktWbJE+/fv144dO1RfX6/bb79d3d3dXpcGwAc41BNAqHzwwQe65JJLdPjwYY0fP97rcgB4jBEdAIF29OhR/fVf/7W+9KUvqaGhQWPGjJEkdXZ2elwZAD/o53UBAGDHrFmz1NTUpKeeekqXXXaZuru7NX78eKXTaa9LA+ADBB0AgfXhhx/qjTfe0Lp163TjjTdKkvbt2+dxVQD8hKADILAuuugiDRs2TOvXr9eIESPU2dmphx56yOuyAPgIPToAAqu+vl4bN27UwYMHNX78eD3wwANauXKl12UB8BFWXQEAgNBiRAcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAIQWQQcAAITW/wOsQ9waoirKpgAAAABJRU5ErkJggg==",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The default `strides(a::AbstractArray)` implementation is deprecated for general arrays.\n",
      "│ Specialize `strides(::LinearAlgebra.Adjoint)` if `LinearAlgebra.Adjoint` indeed uses a strided representation in memory.\n",
      "│ Warning: inappropriately implementing this method for an array type that does not use strided\n",
      "│ storage may lead to incorrect results or segfaults.\n",
      "│   caller = stride at abstractarray.jl:350 [inlined]\n",
      "└ @ Core ./abstractarray.jl:350\n",
      "┌ Warning: The default `strides(a::AbstractArray)` implementation is deprecated for general arrays.\n",
      "│ Specialize `strides(::LinearAlgebra.Adjoint)` if `LinearAlgebra.Adjoint` indeed uses a strided representation in memory.\n",
      "│ Warning: inappropriately implementing this method for an array type that does not use strided\n",
      "│ storage may lead to incorrect results or segfaults.\n",
      "│   caller = stride at abstractarray.jl:350 [inlined]\n",
      "└ @ Core ./abstractarray.jl:350\n"
     ]
    }
   ],
   "source": [
    "using Distributions, PyPlot\n",
    "N = 100\n",
    "generative_dist = MvNormal([0,1.], [0.8 0.5; 0.5 1.0])\n",
    "function plotObservations(obs::Matrix)\n",
    "    plot(obs[1,:]', obs[2,:]', \"kx\", zorder=3)\n",
    "    fill_between([0., 2.], 1., 2., color=\"k\", alpha=0.4, zorder=2) # Shaded area\n",
    "    text(2.05, 1.8, \"S\", fontsize=12)\n",
    "    xlim([-3,3]); ylim([-2,4]); xlabel(\"a\"); ylabel(\"b\")\n",
    "end\n",
    "D = rand(generative_dist, N) # Generate observations from generative_dist\n",
    "plotObservations(D)\n",
    "x_dot = rand(generative_dist) # Generate x∙\n",
    "plot(x_dot[1], x_dot[2], \"ro\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Log-Likelihood for a Multivariate Gaussian (MVG)\n",
    "\n",
    "- Assume we are given a set of IID data points $D=\\{x_1,\\ldots,x_N\\}$, where $x_n \\in \\mathbb{R}^D$. We want to build a model for these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Model specification**: Let's assume a MVG model $x_n=\\mu+\\epsilon_n$ with $\\epsilon_n \\sim \\mathcal{N}(0,\\Sigma)$, or equivalently,\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(x_n|\\mu,\\Sigma) &= \\mathcal{N}(x_n|\\mu,\\Sigma) \n",
    "= |2 \\pi \\Sigma|^{-1/2} \\mathrm{exp} \\left\\{-\\frac{1}{2}(x_n-\\mu)^T\n",
    "\\Sigma^{-1} (x_n-\\mu) \\right\\}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since the data are IID, $p(D|\\theta)$ factorizes as\n",
    "\n",
    "$$  \n",
    "p(D|\\theta) = p(x_1,\\ldots,x_N|\\theta) \\stackrel{\\text{IID}}{=} \\prod_n p(x_n|\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This choice of model yields the following log-likelihood (use (B-C.9) and (B-C.4)),\n",
    "\n",
    "$$\\begin{align*}\n",
    " \\log &p(D|\\theta) = \\log \\prod_n p(x_n|\\theta) = \\sum_n \\log \\mathcal{N}(x_n|\\mu,\\Sigma) \\tag{1}\\\\\n",
    "     &= N \\cdot \\log | 2\\pi\\Sigma |^{-1/2} - \\frac{1}{2} \\sum\\nolimits_{n} (x_n-\\mu)^T \\Sigma^{-1} (x_n-\\mu) \n",
    " \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximum Likelihood estimation of mean of MVG\n",
    "\n",
    "- We want to maximize $\\log p(D|\\theta)$ wrt the parameters $\\theta=\\{\\mu,\\Sigma\\}$. Let's take derivatives; first to mean $\\mu$, (making use of  (B-C.25) and (B-C.27)),\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\nabla_\\mu \\log p(D|\\theta) &= -\\frac{1}{2}\\sum_n \\nabla_\\mu \\left[ (x_n-\\mu)^T \\Sigma^{-1} (x_n-\\mu) \\right] \\\\\n",
    "&= -\\frac{1}{2}\\sum_n \\nabla_\\mu \\mathrm{Tr} \\left[ -2\\mu^T\\Sigma^{-1}x_n + \\mu^T\\Sigma^{-1}\\mu \\right]  \\\\\n",
    "&= -\\frac{1}{2}\\sum_n \\left( -2\\Sigma^{-1}x_n + 2\\Sigma^{-1}\\mu \\right) \\\\\n",
    "&= \\Sigma^{-1}\\,\\sum_n \\left( x_n-\\mu \\right)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Setting the derivative to zero yields the **sample mean**\n",
    "\n",
    "$$\\begin{equation*}\n",
    "\\boxed{\n",
    "\\hat \\mu = \\frac{1}{N} \\sum_n x_n\n",
    "}\n",
    "\\end{equation*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximum Likelihood estimation of variance of MVG\n",
    "\n",
    "- Now we take the gradient of the log-likelihood wrt the **precision matrix** $\\Sigma^{-1}$ (making use of B-C.28 and B-C.24)\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\nabla_{\\Sigma^{-1}}  &\\log p(D|\\theta) \\\\\n",
    "&= \\nabla_{\\Sigma^{-1}} \\left[ \\frac{N}{2} \\log |2\\pi\\Sigma|^{-1} - \\frac{1}{2} \\sum_{n=1}^N (x_n-\\mu)^T \\Sigma^{-1} (x_n-\\mu)\\right] \\\\\n",
    "&= \\nabla_{\\Sigma^{-1}} \\left[ \\frac{N}{2} \\log |\\Sigma^{-1}| - \\frac{1}{2} \\sum_{n=1}^N \\mathrm{Tr} \\left[ (x_n-\\mu) (x_n-\\mu)^T \\Sigma^{-1}\\right] \\right]\\\\\n",
    "&= \\frac{N}{2}\\Sigma -\\frac{1}{2}\\sum_n (x_n-\\mu)(x_n-\\mu)^T\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Get optimum by setting the gradient to zero,\n",
    "$$\\begin{equation*}\n",
    "\\boxed{\n",
    "\\hat \\Sigma = \\frac{1}{N} \\sum_n (x_n-\\hat\\mu)(x_n - \\hat\\mu)^T}\n",
    "\\end{equation*}$$\n",
    "which is also known as the **sample variance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sufficient Statistics\n",
    "\n",
    "- Note that the ML estimates can also be written as\n",
    "$$\\begin{equation*}\n",
    "\\hat \\Sigma = \\sum_n x_n x_n^T - \\left( \\sum_n x_n\\right)\\left( \\sum_n x_n\\right)^T, \\quad \\hat \\mu = \\frac{1}{N} \\sum_n x_n\n",
    "\\end{equation*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- I.o.w., the two statistics (a 'statistic' is a function of the data) $\\sum_n x_n$ and $\\sum_n x_n x_n^T$ are sufficient to estimate the parameters $\\mu$ and $\\Sigma$ from $N$ observations. In the literature, $\\sum_n x_n$ and  $\\sum_n x_n x_n^T$ are called **sufficient statistics** for the Gaussian PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The actual parametrization of a PDF is always a re-parameteriation of the sufficient statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Sufficient statistics are useful because they summarize all there is to learn about the data set in a minimal set of variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution to Example Problem\n",
    "\n",
    "<span class=\"exercise\">\n",
    "We apply maximum likelihood estimation to fit a 2-dimensional Gaussian model ($m$) to data set $D$. Next, we evaluate $p(x_\\bullet \\in S | m)$ by (numerical) integration of the Gaussian pdf over $S$: $p(x_\\bullet \\in S | m) = \\int_S p(x|m) \\mathrm{d}x$.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Package Cubature not found in current path:\n- Run `Pkg.add(\"Cubature\")` to install the Cubature package.\n",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package Cubature not found in current path:\n- Run `Pkg.add(\"Cubature\")` to install the Cubature package.\n",
      "",
      "Stacktrace:",
      " [1] require(::Module, ::Symbol) at ./loading.jl:817",
      " [2] top-level scope at In[2]:1"
     ]
    }
   ],
   "source": [
    "using Cubature # Numerical integration package\n",
    "\n",
    "# Maximum likelihood estimation of 2D Gaussian\n",
    "μ = 1/N * sum(D,2)[:,1]\n",
    "D_min_μ = D - repmat(μ, 1, N)\n",
    "Σ = Hermitian(1/N * D_min_μ*D_min_μ')\n",
    "m = MvNormal(μ, convert(Matrix, Σ))\n",
    "\n",
    "# Contour plot of estimated Gaussian density\n",
    "A = Matrix{Float64}(100,100); B = Matrix{Float64}(100,100)\n",
    "density = Matrix{Float64}(100,100)\n",
    "for i=1:100\n",
    "    for j=1:100\n",
    "        A[i,j] = a = (i-1)*6/100.-2\n",
    "        B[i,j] = b = (j-1)*6/100.-3\n",
    "        density[i,j] = pdf(m, [a,b])\n",
    "    end\n",
    "end\n",
    "c = contour(A, B, density, 6, zorder=1)\n",
    "PyPlot.set_cmap(\"cool\")\n",
    "clabel(c, inline=1, fontsize=10)\n",
    "\n",
    "# Plot observations, x∙, and the countours of the estimated Gausian density\n",
    "plotObservations(D)\n",
    "plot(x_dot[1], x_dot[2], \"ro\")\n",
    "\n",
    "# Numerical integration of p(x|m) over S:\n",
    "(val,err) = hcubature((x)->pdf(m,x), [0., 1.], [2., 2.])\n",
    "println(\"p(x⋅∈S|m) ≈ $(val)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discrete Data: the 1-of-K Coding Scheme\n",
    "\n",
    "- Consider a coin-tossing experiment with outcomes $x \\in\\{0,1\\}$ (tail and head) and let $0\\leq \\mu \\leq 1$ represent the probability of heads. This model can written as a **Bernoulli distribution**:\n",
    "$$ \n",
    "p(x|\\mu) = \\mu^{x}(1-\\mu)^{1-x}\n",
    "$$\n",
    "  - Note that the variable $x$ acts as a (binary) **selector** for the tail or head probabilities. Think of this as an 'if'-statement in programming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **1-of-K coding scheme**. Now consider a $K$-sided coin (a _die_ (pl.: dice)). It is convenient to code the outcomes by $x=(x_1,\\ldots,x_K)^T$ with **binary selection variables**\n",
    "$$\n",
    "x_k = \\begin{cases} 1 & \\text{if die landed on $k$th face}\\\\\n",
    "0 & \\text{otherwise} \\end{cases}\n",
    "$$\n",
    "  - E.g., for $K=6$, if the die lands on the 3rd face $\\,\\Rightarrow x=(0,0,1,0,0,0)^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Assume the probabilities $p(x_k=1) = \\mu_k$ with  $\\sum_k \\mu_k  = 1$. The data generating distribution is then (note the similarity to the Bernoulli distribution)\n",
    "\n",
    "$$\n",
    "p(x|\\mu) = \\mu_1^{x_1} \\mu_2^{x_2} \\cdots \\mu_k^{x_k}=\\prod_k \\mu_k^{x_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This generalized Bernoulli distribution is called the **categorical distribution** (or sometimes the 'multi-noulli' distribution).\n",
    "\n",
    "<!---\n",
    "\n",
    "- Note that $\\sum_k x_k = 1$ and verify for yourself that $\\mathrm{E}[x|\\mu] = \\mu$.\n",
    "- In these notes, we use the superscript to indicate that we are working with a **binary selection variable** in a 1-of-$K$ scheme.\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Categorical vs. Multinomial Distribution\n",
    "\n",
    "- Observe a data set $D=\\{x_1,\\ldots,x_N\\}$  of $N$ IID rolls of a $K$-sided die, with generating PDF\n",
    "$$\n",
    "p(D|\\mu) = \\prod_n \\prod_k \\mu_k^{x_{nk}} = \\prod_k \\mu_k^{\\sum_n x_{nk}} = \\prod_k \\mu_k^{m_k}\n",
    "$$\n",
    "where $m_k= \\sum_n x_{nk}$ is the total number of occurrences that we 'threw' $k$ eyes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This distribution depends on the observations **only** through the quantities $\\{m_k\\}$, with generally $K \\ll N$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A related distribution is the distribution over $D_m=\\{m_1,\\ldots,m_K\\}$, which is called the **multinomial distribution**,\n",
    "$$\n",
    "p(D_m|\\mu) =\\frac{N!}{m_1! m_2!\\ldots m_K!} \\,\\prod_k \\mu_k^{m_k}\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The catagorical distribution $p(D|\\mu) = p(\\,x_1,\\ldots,x_N\\,|\\,\\mu\\,)$ is a distribution over the **observations** $\\{x_1,\\ldots,x_N\\}$, whereas the multinomial distribution $p(D_m|\\mu) = p(\\,m_1,\\ldots,m_K\\,|\\,\\mu\\,)$ is a distribution over the **data frequencies** $\\{m_1,\\ldots,m_K\\}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximum Likelihood Estimation for the Multinomial\n",
    "\n",
    "- Now let's find the ML estimate for $\\mu$, based on $N$ throws of a $K$-sided die. Again we use the shorthand $m_k \\triangleq \\sum_n x_{nk}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The log-likelihood for the multinomial distribution is given by\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathrm{L}(\\mu) &\\triangleq \\log p(D_m|\\mu) \\propto \\log \\prod_k \\mu_k^{m_k} =  \\sum_k m_k \\log \\mu_k \\tag{2}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When doing ML estimation, we must obey the constraint $\\sum_k \\mu_k  = 1$, which can be accomplished by a <span style=\"color:red\">Lagrange multiplier</span>. The **augmented log-likelihood** with Lagrange multiplier is then\n",
    "\n",
    "$$\n",
    "\\mathrm{L}^\\prime(\\mu) = \\sum_k m_k \\log \\mu_k  + \\lambda \\cdot (1 - \\sum_k \\mu_k )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Set derivative to zero yields the **sample proportion** for $\\mu_k$ \n",
    "\n",
    "$$\\begin{equation*}\n",
    "\\nabla_{\\mu_k}   \\mathrm{L}^\\prime = \\frac{m_k }\n",
    "{\\hat\\mu_k } - \\lambda  \\overset{!}{=} 0 \\; \\Rightarrow \\; \\boxed{\\hat\\mu_k = \\frac{m_k }{N}}\n",
    "\\end{equation*}$$\n",
    "\n",
    "where we get $\\lambda$ from the constraint \n",
    "\n",
    "$$\\begin{equation*}\n",
    "\\sum_k \\hat \\mu_k = \\sum_k \\frac{m_k}\n",
    "{\\lambda} = \\frac{N}{\\lambda} \\overset{!}{=}  1\n",
    "\\end{equation*}$$\n",
    "\n",
    "<!---\n",
    "- Interesting special case: **Binomial** (=$N$ coin tosses): \n",
    "$$p(x_n|\\theta)= \\theta^{[x_n=h]}(1-\\theta)^{[x_n=t]}=\\theta_h^{[x_n=h]} \\theta_t^{[x_n=t]}\n",
    "$$ \n",
    "yields $$\\hat \\theta = \\frac{N_h}{N_h +N_t} $$\n",
    "\n",
    "- Compare this answer to Laplace's rule for predicting the next coin toss (in probability theory lesson) $$p(\\,x_\\bullet=h\\,|\\,\\theta\\,)=\\frac{N_h+1}{N_h +N_t+2}\\,.$$ What is the source of the difference?\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap ML for Density Estimation\n",
    "\n",
    "Given $N$ IID observations $D=\\{x_1,\\dotsc,x_N\\}$.\n",
    "\n",
    "- For a **multivariate Gaussian** model $p(x_n|\\theta) = \\mathcal{N}(x_n|\\mu,\\Sigma)$, we obtain ML estimates\n",
    "\n",
    "$$\\begin{align}\n",
    "\\hat \\mu &= \\frac{1}{N} \\sum_n x_n \\tag{sample mean} \\\\\n",
    "\\hat \\Sigma &= \\frac{1}{N} \\sum_n (x_n-\\hat\\mu)(x_n - \\hat \\mu)^T \\tag{sample variance}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For discrete outcomes modeled by a 1-of-K **categorical distribution** we find\n",
    "\n",
    "$$\\begin{align}\n",
    "\\hat\\mu_k  = \\frac{1}{N} \\sum_n x_{nk} \\quad \\left(= \\frac{m_k}{N} \\right) \\tag{sample proportion}\n",
    "\\end{align}$$\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " \n",
    "- Note the similarity for the means between discrete and continuous data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We didn't use a co-variance matrix for discrete data. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---\n",
    "The cell below loads the style file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--\n",
       "This HTML file contains custom styles and some javascript.\n",
       "Include it a Jupyter notebook for improved rendering.\n",
       "-->\n",
       "\n",
       "<!-- Fonts -->\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Nixie+One' rel='stylesheet' type='text/css'>\n",
       "\n",
       "<!-- Custom style -->\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "#notebook_panel { /* main background */\n",
       "    background: rgb(245,245,245);\n",
       "}\n",
       "\n",
       "div.container {\n",
       "    min-width: 960px;\n",
       "}\n",
       "\n",
       "div #notebook { /* centre the content */\n",
       "    background: #fff; /* white background for content */\n",
       "    margin: auto;\n",
       "    padding-left: 0em;\n",
       "}\n",
       "\n",
       "#notebook li { /* More space between bullet points */\n",
       "    margin-top:0.8em;\n",
       "}\n",
       "\n",
       "/* draw border around running cells */\n",
       "div.cell.border-box-sizing.code_cell.running {\n",
       "    border: 1px solid #111;\n",
       "}\n",
       "\n",
       "/* Put a solid color box around each cell and its output, visually linking them*/\n",
       "div.cell.code_cell {\n",
       "    background-color: rgb(256,256,256);\n",
       "    border-radius: 0px;\n",
       "    padding: 0.5em;\n",
       "    margin-left:1em;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render{\n",
       "    font-family: 'Alegreya Sans' sans-serif;\n",
       "    line-height: 140%;\n",
       "    font-size: 125%;\n",
       "    font-weight: 400;\n",
       "    width:800px;\n",
       "    margin-left:auto;\n",
       "    margin-right:auto;\n",
       "}\n",
       "\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-style:regular;\n",
       "    font-weight: 400;\n",
       "    font-size: 45pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-top: 0.5em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 30pt;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0,51,102);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.3em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Nixie One', serif;\n",
       "    margin-top:16px;\n",
       "    font-size: 22pt;\n",
       "    font-weight: 600;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: regular;\n",
       "    color: rgb(102,102,0);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {    /*Use this for captions*/\n",
       "    font-family: 'Nixie One', serif;\n",
       "    font-size: 14pt;\n",
       "    text-align: center;\n",
       "    margin-top: 0em;\n",
       "    margin-bottom: 2em;\n",
       "    font-style: regular;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {  /*Use this for small titles*/\n",
       "    font-family: 'Nixie One', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 16pt;\n",
       "    color: rgb(163,0,0);\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.8em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 { /*use this for copyright note*/\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 9pt;\n",
       "    line-height: 100%;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "    font-family: \"PT Mono\";\n",
       "    font-size: 90%;\n",
       "}\n",
       "\n",
       ".boxed { /* draw a border around a piece of text */\n",
       "  border: 1px solid blue ;\n",
       "}\n",
       "\n",
       "h4#CODE-EXAMPLE,\n",
       "h4#END-OF-CODE-EXAMPLE {\n",
       "    margin: 10px 0;\n",
       "    padding: 10px;\n",
       "    background-color: #d0f9ca !important;\n",
       "    border-top: #849f81 1px solid;\n",
       "    border-bottom: #849f81 1px solid;\n",
       "}\n",
       "\n",
       ".emphasis {\n",
       "    color: red;\n",
       "}\n",
       "\n",
       ".exercise {\n",
       "    color: green;\n",
       "}\n",
       "\n",
       ".proof {\n",
       "    color: blue;\n",
       "}\n",
       "\n",
       "code {\n",
       "  padding: 2px 4px !important;\n",
       "  font-size: 90% !important;\n",
       "  color: #222 !important;\n",
       "  background-color: #efefef !important;\n",
       "  border-radius: 2px !important;\n",
       "}\n",
       "\n",
       "/* This removes the actual style cells from the notebooks, but no in print mode\n",
       "   as they will be removed through some other method */\n",
       "@media not print {\n",
       "  .cell:nth-last-child(-n+2) {\n",
       "    display: none;\n",
       "  }\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n",
       "<!-- MathJax styling -->\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"],\n",
       "                           equationNumbers: { autoNumber: \"AMS\", useLabelIds: true}\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `readstring(s::IO)` is deprecated, use `read(s, String)` instead.\n",
      "│   caller = #3 at In[3]:2 [inlined]\n",
      "└ @ Core ./In[3]:2\n"
     ]
    }
   ],
   "source": [
    "open(\"../../styles/aipstyle.html\") do f\n",
    "    display(\"text/html\", readstring(f))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
