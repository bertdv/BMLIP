{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EXERCISES WITH SOLUTIONS\n",
    "\n",
    "### Bayesian Machine Learning and Information Processing (5SSD0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prelude \n",
    "\n",
    "- In this notebook, we provide a set of exercises that should help you prepare for the exam. There are two sets of exercises: \n",
    "  1. (**5SSB0**). The first set contains questions from previous exams of class 5SSB0 (Adaptive Information Processing). 5SSB0 was last taught at TU/e in the academic year 2018/19. Starting with the academic year 2019/20, the current class (5SSD0) is offered instead. In comparison to 5SSB0, the emphasis of the current class is more on the Bayesian framework, rather than maximum likelihood. Below, we present a selection of exercises that were used in the 5SSB0 exams. While these exercises may not represent the emphasis on Bayesian methods, they do represent the \"style of questions\" and the \"level of difficulty\" that you may expect in upcoming 5SSD0 exams. Also, there is nothing in the questions below that is considered outside the scope of 5SSD0. \n",
    "  2. (**Rehearsal**). A second set of exercises are categorized by lesson headers, e.g., \"Probability Theory\" or \"Generative Classification\". These exercises intend to test you on the contents of the corresponing lesson. Of course, for some exercises you may need some contents of some other (usually earlier) lessons or background materials. A perfect categorization is not feasible, but we've tried to link each question to a lesson so as to make it easier to test yourself after studying a specific lesson.     \n",
    "  \n",
    "- For some of these exercises you will be able to find solutions quickly on the internet. Try to resist this route to solving the problems. You will not be graded for these exercises and solutions will be made available in a separate notebook. **Your ability to solve these exercises without external help provides an excellent indicator of your readiness to pass the exam**. \n",
    "\n",
    "- This notebook is still under construction. We will be adding more exercises to help you prepare. Also, not all solutions are provided yet. We are working on this too. If you absolutely need the solution for a problem that doesn't have a solution yet, please contact one of the TAs (see http://bmlip.nl for contact info.)\n",
    "\n",
    "- As 2019/20 is the first time we teach this class, please be alert to errors (and let us know if you find any!) or more generally, let us know if things are unclear to you or if a question can be improved. \n",
    "\n",
    "- We are aware there are some rendering problems in some browsers. We are trying to fix that as well. \n",
    "\n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cheatsheet\n",
    "\n",
    "- You are not allowed to bring books or notes to the exam. Instead, feel free to make use of the following cheatsheet as we will provide this or a similar cheatsheet in an appendix of the exam papers.\n",
    "\n",
    "- Some <a id=matrix-calculus>Matrix Calculus</a>, see also Bishop, appendix C.  \n",
    "$$\\begin{align*}\n",
    "|A^{-1}|&=|A|^{-1} \\\\\n",
    "\\nabla_A \\log |A| &= (A^{T})^{-1} = (A^{-1})^T \\\\\n",
    "\\mathrm{Tr}[ABC]&= \\mathrm{Tr}[CAB] = \\mathrm{Tr}[BCA]  \\\\\n",
    "\\nabla_A \\mathrm{Tr}[AB] &=\\nabla_A \\mathrm{Tr}[BA]= B^T  \\\\\n",
    "\\nabla_A \\mathrm{Tr}[ABA^T] &= A(B+B^T)\\\\\n",
    " \\nabla_x x^TAx &= (A+A^T)x\\\\\n",
    "\\nabla_X a^TXb &= \\nabla_X \\mathrm{Tr}[ba^TX] = ab^T\n",
    "\\end{align*}$$\n",
    "\n",
    "- Definition of the Multivariate Gaussian Distribution (MVG)\n",
    "$$\n",
    "\\mathcal{N}(x|\\,\\mu,\\Sigma) = |2 \\pi \\Sigma|^{-\\frac{1}{2}} \\exp\\left\\{-\\frac{1}{2}(x-\\mu)^T\n",
    "\\Sigma^{-1} (x-\\mu) \\right\\}\n",
    "$$\n",
    "\n",
    "- A **linear transformation** $z=Ax+b$ of a Gaussian variable $\\mathcal{N}(x|\\mu,\\Sigma)$ is Gaussian distributed as\n",
    "$$\n",
    "p(z) = \\mathcal{N} \\left(z \\,|\\, A\\mu+b, A\\Sigma A^T \\right) \n",
    "$$\n",
    "\n",
    "- **Multiplication** of 2 Gaussian distributions\n",
    "$$ \n",
    " \\mathcal{N}(x|\\mu_a,\\Sigma_a) \\cdot  \\mathcal{N}(x|\\mu_b,\\Sigma_b) = \\alpha \\cdot \\mathcal{N}(x|\\mu_c,\\Sigma_c)\n",
    "$$\n",
    "with\n",
    "$$\\begin{align*}\n",
    "\\Sigma_c^{-1} &= \\Sigma_a^{-1} + \\Sigma_b^{-1} \\\\\n",
    "\\Sigma_c^{-1}\\mu_c &= \\Sigma_a^{-1}\\mu_a + \\Sigma_b^{-1}\\mu_b \\\\\n",
    "\\alpha &= \\mathcal{N}(\\mu_a | \\mu_b, \\Sigma_a + \\Sigma_b)\n",
    "\\end{align*}$$\n",
    "\n",
    "- **Conditioning** and **marginalization** of Gaussians. Let $z = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$ be jointly normal distributed as\n",
    "$$\\begin{align*}\n",
    "p(z) &= \\mathcal{N}(z | \\mu, \\Sigma) \n",
    "  =\\mathcal{N} \\left( \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\,\\left|\\, \\begin{bmatrix} \\mu_x \\\\ \\mu_y \\end{bmatrix}, \n",
    "  \\begin{bmatrix} \\Sigma_x & \\Sigma_{xy} \\\\ \\Sigma_{yx} & \\Sigma_y \\end{bmatrix} \\right. \\right)\\,,\n",
    "\\end{align*}$$\n",
    "then $p(z) = p(y|x)\\cdot p(x)$, with \n",
    "$$\\begin{align*}\n",
    "p(y|x) &= \\mathcal{N}\\left(y\\,|\\,\\mu_y + \\Sigma_{yx}\\Sigma_x^{-1}(x-\\mu_x),\\, \\Sigma_y - \\Sigma_{yx}\\Sigma_x^{-1}\\Sigma_{xy} \\right) \\\\\n",
    "p(x) &= \\mathcal{N}\\left( x\\,|\\,\\mu_x, \\Sigma_x \\right)\n",
    "\\end{align*}$$\n",
    "\n",
    "- For a binary variable $x \\in \\{0,1\\}$, the **Bernoulli** distribution is given by\n",
    "$$ \n",
    "p(x|\\mu) = \\mu^{x}(1-\\mu)^{1-x}\n",
    "$$\n",
    "\n",
    "- The conjugate prior for $\\mu$ is the **Beta** distribution, given by\n",
    "$$\n",
    "p(\\mu) = \\mathcal{B}(\\mu|\\alpha,\\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\mu^{\\alpha-1}(1-\\mu)^{\\beta-1}\n",
    "$$\n",
    "where $\\alpha$ and $\\beta$ are \"hyperparameters\" that you can set to reflect your prior beliefs about $\\mu$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Selected exercises from previous exams \"5SSB0\"\n",
    "\n",
    "\n",
    "- **[1]** Answer shortly (max. 3 sentences): What is the difference between supervised and unsupervised learning?       \n",
    "  > Supervised learning concerns learning a map from inputs to targets. Unsupervised learning concerns analysis of data without targets, such as pattern discovery and compression. (Alternative answers may also be accepted.)     \n",
    "\n",
    "- **[2]** Which of the following statements is true (or justified)?                 \n",
    "  (a) If $X$ and $Y$ are independent Gaussian distributed variables, then $Z = 3X+Y$ is also a Gaussian distributed variable.     \n",
    "  (b) The sum of two Gaussian functions is always also a Gaussian function.      \n",
    "  (c) Discriminative classification is more similar to regression than to density estimation.     \n",
    "  (d) Density estimation is more similar to generative classification than to discriminative classification.     \n",
    "  (e) Clustering is more similar to supervised classification than to unsupervised classification.     \n",
    "  > a, c, d\n",
    "\n",
    "- **[3]** Consider a binary classification problem with two classes $\\{y_1,y_2\\}$ and input vector $x$. Outputs $y_k$ are recorded by a one-hot encoding scheme. We are given a data set to train the parameters $\\theta$ for a likelihood model of the form\n",
    "$$\n",
    "p(y_k=1|x,\\theta) = \\frac{1}{1 + e^{-\\theta_k^T x}}\n",
    "$$\n",
    "There a two fundamentally different ways to train $\\theta$, namely through a generative model or by discriminative training.     \n",
    "  (a) Explain shortly how we train $\\theta$ through a generative model. No need to work out all equations for Gaussian models, but explain the strategy in probabilistic modeling terms.     \n",
    "  (b) Explain shortly how we train $\\theta$ through a discriminative\n",
    "approach.  \n",
    "> (a) In a generative model, the class posterior is obtained through\n",
    "Bayes rule,\n",
    "$$\n",
    "p(y_k=1|x,\\theta) \\propto p(x|y_k=1,\\theta) p(y_k=1|\\theta)\n",
    "$$\n",
    "In terms of ML training, this means we maximize the *joint* log-likelihood $\\sum_n \\log p(x_n,y_n|\\theta)$ wrt $\\theta$. This leads to a structured breakdown of the model (and parameters) into a class-conditional likelihood $ p(x|y_k=1,\\theta) $ and class priors $p(y_k=1|\\theta)$.     \n",
    "> (b) In a discriminative model, the posterior class density\n",
    "$ p(y_k=1|x,\\theta) $  is directly trained, i.o.w. we maximize the\n",
    "*conditional* log-likelihood $\\sum_n \\log p(y_{nk}|x_n,\\theta)$.\n",
    "There's no structured model breakdown.\n",
    "\n",
    "- **[4]** What is the difference between supervised and unsupervised learning? Express the goals of these two learning methods in terms of a probability distribution. (I'm looking here for a statement such as: \" Given $\\ldots$, the goals of supervised/unsupervised learning is to estimate $p(\\cdot|\\cdot)$\".)      \n",
    "> Given data $D=\\{(x_1,y_1),\\ldots,(x_N,y_N)\\}$ and a model $p(y|x,\\theta)$, the goal of supervised learning is to estimate $p(\\theta|D)$. Given data $D=\\{x_1,\\ldots,x_N\\}$ and a model $p(x|\\theta)$, the goal of unsupervised learning is to estimate $p(\\theta|D)$. \n",
    "\n",
    "- **[5]** In a particular model with hidden variables, the log-likelihood can be worked out to the following expression:\n",
    "$$\n",
    " L(\\theta) = \\sum_n \\log \\left(\\sum_k \\pi_k\\,\\mathcal{N}(x_n|\\mu_k,\\Sigma_k)\\right)\n",
    "$$\n",
    "Do you prefer a gradient descent or EM algorithm to estimate maximum likelihood values for the parameters?  Explain your answer. (No need to work out the equations.)\n",
    "> Since this expression does not degenerate into simple MVGs, the EM approach is in practice preferred.\n",
    "\n",
    "- **[6]** Consider a data set $D = \\{x_1,x_2,\\ldots,x_N\\}$ where we assume that each sample $x_n$ is IID distributed by a multivariate Gaussian (MVG) $\\mathcal{N}(x_n|\\,\\mu,\\Sigma)$. \n",
    "Proof that the maximum likelihood estimate (MLE) of the mean value of this distribution is given by\n",
    "$$\\begin{equation*}\n",
    "\\hat \\mu = \\frac{1}{N}\\sum_n x_n \n",
    "\\end{equation*}$$ \n",
    "(Note the list of [matrix calculus formulas](#matrix-calculus) above).\n",
    "> $$\\begin{align*}\n",
    "\\nabla_\\mu \\log p(D|\\theta) &\\propto -\\frac{1}{2}\\sum_n \\nabla_\\mu \\left( (x_n-\\mu)^T \\Sigma^{-1} (x_n-\\mu) \\right)  \\\\\n",
    "&= -\\frac{1}{2}\\sum_n \\nabla_\\mu \\left( -2\\mu^T\\Sigma^{-1}x_n + \\mu^T\\Sigma^{-1}\\mu \\right) \\\\\n",
    "&= -\\frac{1}{2}\\sum_n \\left( -2\\Sigma^{-1} x_n + 2\\Sigma^{-1}\\mu \\right)  \\\\\n",
    "&= \\Sigma^{-1}\\,\\sum_n \\left( x_n-\\mu \\right)\n",
    "\\end{align*}$$\n",
    "Set to zero yields\n",
    "$$\\begin{equation*}\n",
    "\\hat \\mu = \\frac{1}{N} \\sum_n x_n\n",
    "\\end{equation*}$$\n",
    "\n",
    "- **[7]** Consider a data set $D = \\{(x_1,y_1), (x_2,y_2),\\dots,(x_N,y_N)\\}$ with 1-of-$K$ notation for the discrete classes, i.e.,\n",
    "\n",
    "$$ y_{nk} = \\begin{cases} 1 & \\text{if $y_n$ in $k$th class}\\\\\n",
    "        0 & \\text{otherwise} \n",
    "        \\end{cases}$$\n",
    "\n",
    "together with class-conditional distribution $p(x_n| y_{nk}=1,\\theta) = \\mathcal{N}(x_n|\\mu_k,\\Sigma)$ and multinomial prior $p(y_{nk}=1) = \\pi_k$.       \n",
    "  (a) Proof that the joint log-likelihood is given by\n",
    "$$\\begin{equation*}\n",
    "\\log p(D|\\theta) =  \\sum_{n,k} y_{nk} \\log \\mathcal{N}(x_n|\\mu_k,\\Sigma) + \\sum_{n,k} y_{nk} \\log \\pi_k\n",
    "\\end{equation*}$$\n",
    "  > $$\\begin{align*}\n",
    " \\log p(D|\\theta) &= \\sum_n \\log \\prod_k p(x_n,y_{nk}|\\theta)^{y_{nk}} \\\\\n",
    "     &=  \\sum_{n,k} y_{nk} \\log p(x_n,y_{nk}|\\theta)\\\\\n",
    "     &=  \\sum_{n,k} y_{nk} \\log \\mathcal{N}(x_n|\\mu_k,\\Sigma) + \\sum_{n,k} y_{nk} \\log \\pi_k\n",
    " \\end{align*}$$ \n",
    " \n",
    "  (b) Show now that the MLE of the *class-conditional* mean is given by\n",
    "$$\\begin{equation*}\n",
    " \\hat \\mu_k = \\frac{\\sum_n y_{nk} x_n}{\\sum_n y_{nk}} \n",
    "\\end{equation*}\n",
    "$$\n",
    "  > \n",
    "\n",
    "- **[8]** Consider an IID data set $D=\\{(x_1,y_1),\\ldots,(x_N,y_N)\\}$. We will model this data set by a model $$y_n =\\theta^T  f(x_n) + e_n\\,,$$ where $f(x_n)$ is an $M$-dimensional feature vector of input $x_n$; $y_n$ is a scalar output and $e_n \\sim \\mathcal{N}(0,\\sigma^2)$.               \n",
    "  (a) Rewrite the model in matrix form by lumping input features in a matrix $F=[f(x_1),\\ldots,f(x_N)]^T$, outputs and noise in the vectors $y=[y_1,\\ldots,y_N]^T$ and $e=[e_1,\\ldots,e_N]^T$, respectively.    \n",
    "  > $y = F\\theta + e$\n",
    "\n",
    "  (b) Now derive an expression for the log-likelihood $\\log p(y|\\,F,\\theta,\\sigma^2)$. \n",
    "  > $$\\begin{align*}\n",
    " \\log p(D|\\theta,\\sigma^2) &= \\log \\mathcal{N}(y|\\,F\\theta ,\\sigma^2)\\\\\n",
    "    &\\propto  -\\frac{1}{2\\sigma^2}\\left( {y - F\\theta } \\right)^T \\left( {y - F\\theta } \\right)\n",
    "\\end{align*}$$\n",
    "\n",
    "  (c) Proof that the maximum likelihood estimate for the parameters is given by \n",
    "$$\\hat\\theta_{\\text{ml}} = (F^TF)^{-1}F^Ty$$   \n",
    "(Note the list of [matrix calculus formulas](#matrix-calculus) above).    \n",
    "  > Taking the derivative to $\\theta$\n",
    "$$\n",
    "\\nabla_\\theta \\log p(D|\\theta) = \\frac{1}{\\sigma^2} F^T(y-F\\theta)\n",
    "$$\n",
    "  Set derivative to zero for maximum likelihood estimate\n",
    "$$\n",
    "\\hat\\theta_{\\text{ml}} = (F^TF)^{-1}F^Ty\n",
    "$$\n",
    "\n",
    "  (d) What is the predicted output value $y_\\bullet$, given an observation $x_\\bullet$ and the maximum likelihood parameters $\\hat \\theta_{\\text{ml}}$. Work this expression out in terms of $F$, $y$ and $f(x_\\bullet)$.      \n",
    "  > Prediction of new data point: $\\hat y_\\bullet = \\hat \\theta^T f(x_\\bullet) = \\left((F^TF)^{-1}F^Ty\\right)^T  f(x_\\bullet) $\n",
    "\n",
    "  (e) Suppose that, before the data set $D$ was observed, we had reason to assume a prior distribution $p(\\theta)=\\mathcal{N}(0,\\sigma_0^2)$. Derive the Maximum a posteriori (MAP) estimate $\\hat \\theta_{\\text{map}}$.(hint: work this out in the $\\log$ domain.)                \n",
    "  >  $$\\begin{align*}\n",
    "\\log p(\\theta|D) &\\propto \\log p(D|\\theta) p(\\theta) \\\\\n",
    "    &\\propto  -\\frac{1}{2\\sigma^2}\\left( {y - F\\theta } \\right)^T \\left( {y - F\\theta } \\right) + \\frac{1}{2 \\sigma_0^2}\\theta^T \\theta\n",
    "\\end{align*}$$\n",
    "  Derivative $\\nabla_\\theta \\log p(\\theta|D) = -(1/\\sigma^2)F^T(y-F\\theta) + (1/ \\sigma_0^2) \\theta$     \n",
    "  Set derivative to zero for MAP estimate leads to \n",
    "$$\\hat\\theta_{\\text{map}} = \\left(F^T F + \\frac{\\sigma^2}{\\sigma_0^2} I\\right)^{-1}F^Ty$$\n",
    "\n",
    "- **[9]** For each of the following sub-questions, provide a *short but essential* answer.      \n",
    "  (a) The joint distribution for feature vector $x$ and membership of $k$th class is given by (we use one-hot encoding of classes)\n",
    "$$p(x,y_k=1) =  \\pi_k \\cdot \\mathcal{N}(x |\\mu_k,\\Sigma)$$ \n",
    "Write down an expression for the posterior class probability $p(y_k=1|x)$ (No derivations are needed, just a proper expression)?     \n",
    "  > $$\n",
    "p(y_k=1|x) = \\frac{\\pi_k \\cdot \\mathcal{N}(x | \\mu_k,\\Sigma)}{\\sum_j \\pi_j \\cdot \\mathcal{N}(x | \\mu_j,\\Sigma)}\n",
    "$$\n",
    "\n",
    "  (b) Why does maximum likelihood estimation become a better approximation to Bayesian learning as you collect more data?     \n",
    "  > The likelihood tends to get 'narrower' and more informative than the prior, since the latter does not change with more data.\n",
    "\n",
    "  (c) Given is a model \n",
    "$$\\begin{align*}\n",
    "p(x|z) &= \\mathcal{N}(x | W z,\\Psi) \\\\\n",
    "p(z) &=  \\mathcal{N}(z|0,I)\n",
    "\\end{align*}$$ \n",
    "Work out an expression for the marginal distribution $p(x)$.     \n",
    "  > $p(x) =  \\mathcal{N}(x|0,W W^T + \\Psi)$ \n",
    "\n",
    "- **[10]** Explain shortly how Bayes rule relates to machine learning in the context of an observed data set $D$ and a model $M$ with parameters $\\theta$. Your answer must contain the expression for Bayes rule.      \n",
    "> Machine learning is inference over models (hypotheses, parameters, etc.) from a given data set. Bayes rule makes this statement precise. Let $\\theta \\in \\Theta$ and $D$ represent a model parameter vector and the given data set, respectively. Then, Bayes rule,\n",
    "$$\n",
    "p(\\theta|D,M) = \\frac{p(D|\\theta,M)}{p(D|M)} p(\\theta|M)\n",
    "$$\n",
    "relates the information that we have about $\\theta$ before we saw the data (i.e., the distribution $p(\\theta,M)$) to what we know after having seen the data, $p(\\theta|D,M)$.\n",
    "\n",
    "- **[11]** Consider the following state-space model:\n",
    "$$\\begin{align*}\n",
    "z_k &= A z_{k-1} + w_k \\\\\n",
    "x_k &= C z_k + v_k \n",
    "\\end{align*}$$\n",
    "where $k=1,2,\\ldots,n$ is the time step counter; $z_k$ is  an *unobserved* state sequence; $x_k$ is an *observed* sequence; $w_k \\sim \\mathcal{N}(0,\\Sigma_w)$ and $v_k \\sim \\mathcal{N}(0,\\Sigma_v)$ are (unobserved) state and observation noise sequences respectively; $z_0 \\sim \\mathcal{N}(0,\\Sigma_0)$ is the initial state and $A$, $C$, $\\Sigma_v$,$\\Sigma_w$ and $\\Sigma_0$ are known parameters. The Forney-style factor graph (FFG) for one time step is depicted here:\n",
    "\n",
    "<img src=\"./i/ffg-5SSB0-exam-Kalman-filter.png\" style=\"width:500px;\">\n",
    "\n",
    "  (a) Rewrite the state-space equations as a set of conditional probability distributions.                 \n",
    "  $$\\begin{align*}\n",
    " p(z_k|z_{k-1},A,\\Sigma_w) &= \\ldots \\\\\n",
    " p(x_k|z_k,C,\\Sigma_v) &= \\ldots \\\\\n",
    " p(z_0|\\Sigma_0) &= \\ldots\n",
    "\\end{align*}$$  \n",
    "  > $$\\begin{align*}\n",
    " p(z_k|z_{k-1},A,\\Sigma_w) &= \\mathcal{N}(z_k|A z_{k-1},\\Sigma_w) \\\\\n",
    " p(x_k|z_k,C,\\Sigma_v) &= \\mathcal{N}(x_k|C z_k,\\Sigma_v) \\\\\n",
    "  p(z_0|\\Sigma_0) &= \\mathcal{N}(z_0|0,\\Sigma_0)\n",
    "\\end{align*}$$ \n",
    "\n",
    "  (b) Define $z^n \\triangleq (z_0,z_1,\\ldots,z_n)$, $x^n \\triangleq (x_1,\\ldots,x_n)$ and $\\theta=\\{A,C,\\Sigma_w,\\Sigma_v\\}$. Now write out the generative model $p(x^n,z^n|\\theta)$ as a product of factors.     \n",
    "  > $$\\begin{align*}\n",
    "p(x^n,z^n|\\theta) &= p(z_0|\\Sigma_0) \\prod_{k=1}^n p(x_k|z_k,C,\\Sigma_v) \\,p(z_k|z_{k-1},A,\\Sigma_w) \\\\\n",
    "  &= \\mathcal{N}(z_0|0,\\Sigma_0) \\prod_{k=1}^n  \\mathcal{N}(x_k|C z_k,\\Sigma_v) \\,\\mathcal{N}(z_k|A z_{k-1},\\Sigma_w)\n",
    "\\end{align*}$$\n",
    "\n",
    "  (c) We are interested in estimating $z_k$ from a given estimate for $z_{k-1}$ and the current observation $x_k$, i.e., we are interested in computing $p(z_k|z_{k-1},x_k,\\theta)$. Can $p(z_k|z_{k-1},x_k,\\theta)$ be expressed as a Gaussian distribution? Explain why or why not in one sentence.    \n",
    "  > Yes, since the generative model $p(x^n,z^n|\\theta)$ is (one big) Gaussian.\n",
    "\n",
    "  (d) Copy the graph onto your exam paper and draw the message passing schedule for computing $p(z_k|z_{k-1},x_k,\\theta)$ by drawing arrows in the factor graph. Indicate the order of the messages by assigning numbers to the arrows.      \n",
    "  > <img src=\"./i/ffg-5SSB0-exam-Kalman-filter-wMessages-wUncertainSigmaV.png\" style=\"width:500px;\">\n",
    "\n",
    "  (e) Now assume that our belief about parameter $\\Sigma_v$ is instead given by a distribution $p(\\Sigma_v)$ (rather than a known value). Adapt the factor graph drawing of the previous answer to reflects our belief about $\\Sigma_v$.      \n",
    "  > See drawing in previous answer. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Rehearsal Exercises\n",
    "\n",
    "- Below you will find more questions that test your knowledge of each lesson. My perception of the difficulty level of each question may differ from yours, but I ll indicate my ratings with three levels, (#) for easy, (##) for intermediate level and (###) for (very) challenging. While all questions are in principle within the scope of the lessons, there should be enough questions of levels (#) and (##) in the exams to pass the class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Machine Learning Overview\n",
    "\n",
    "- **[1]** (##) Pick three applications from the [\"Some Machine Learning Applications\"](https://nbviewer.jupyter.org/github/bertdv/BMLIP/blob/master/lessons/notebooks/Machine-Learning-Overview.ipynb#some-ml-apps)-slide and (shortly) describe for each application how (a combination of) clustering, dimensionality reduction, regression classification or reinforcement learning could accomplish the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probability Theory Review\n",
    "\n",
    "\n",
    "- **[1]** (a) (#) Proof that the \"elementary\" sum rule $p(A) + p(\\bar{A}) = 1$ follows from the (general) sum rule $$p(A+B) = p(A) + p(B) - p(A,B)\\,.$$     \n",
    "  (b) (###) Conversely, derive the general sum rule\n",
    "    $p(A + B) = p(A) + p(B) - p(A,B)$\n",
    "from the elementary sum rule $p(A) + p(\\bar A) = 1$ and the product rule. Here, you may make use of the (Boolean logic) fact that $A + B = \\overline {\\bar A \\bar B }$.      \n",
    "  > $$\\begin{align*}\n",
    "  p\\left( {A + B} \\right)  &\\underset{\\mathrm{bool}}{=}  p\\left( {\\overline {\\bar A \\bar B } } \\right) \\\\\n",
    "    &\\underset{\\mathrm{sum}}{=} 1 - p\\left( {\\bar A \\bar B } \\right) \\\\\n",
    "    &\\underset{\\mathrm{prod}}{=} 1 - p\\left( {\\bar A |\\bar B } \\right)p\\left( {\\bar B } \\right) \\\\\n",
    "    &\\underset{\\mathrm{sum}}{=} 1 - \\left( {1 - p\\left( {A|\\bar B } \\right)} \\right)\\left( {1 - p\\left( B \\right)} \\right) \\\\\n",
    "    &= p(B) + \\left( {1 - p\\left( B \\right)} \\right)p\\left( {A|\\bar B } \\right)  \\\\\n",
    "    &\\underset{\\mathrm{prod}}{=} p(B) + \\left( {1 - p\\left( B \\right)} \\right)p\\left( {\\bar B |A} \\right)\\frac{{p\\left( A \\right)}}\n",
    "{{p\\left( {\\bar B } \\right)}} \\\\\n",
    "    &\\underset{\\mathrm{sum}}{=} p(B) + p\\left( {\\bar B |A} \\right)p\\left( A \\right) \\\\\n",
    "    &\\underset{\\mathrm{sum}}{=} p(B) + \\left( {1 - p\\left( {B|A} \\right)} \\right)p\\left( A \\right)  \\\\\n",
    "    &\\underset{\\mathrm{sum}}{=} p\\left( A \\right) + p(B) - p\\left( {A,B} \\right) \n",
    "\\end{align*}$$\n",
    "  Note that, aside from the first boolean rewrite, everything follows straight application of sum and product rules. \n",
    "\n",
    "- **[2]** Box 1 contains 8 apples and 4 oranges. Box 2 contains 10 apples and 2 oranges. Boxes are chosen with equal probability.     \n",
    "  (a) (#) What is the probability of choosing an apple?        \n",
    "  (b) (##) If an apple is chosen, what is the probability that it came from box 1?\n",
    "> The following probabilities are given in the problem statement,\n",
    "$$\\begin{align*}\n",
    "p(b_1) &= p(b_2) = 1/2\\\\\n",
    "p(a|b_1) &= 8/12,  \\quad p(a|b_2)=10/12\\\\\n",
    "p(o|b_1) &= 4/12,  \\quad p(o|b_2)=2/12\n",
    "\\end{align*}$$\n",
    "> \n",
    "> (a) $p(a) = \\sum_i p(a,b_i) = \\sum_i p(a|b_i)p(b_i)=\\frac{8}{12}\\cdot\\frac{1}{2} + \\frac{10}{12}\\cdot\\frac{1}{2} = \\frac{3}{4}$       \n",
    "> (b) $p(b_1|a) = \\frac{p(a,b_1)}{p(a)} = \\frac{p(a|b_1)p(b_1)}{p(a)} = \\frac{\\frac{8}{12}\\cdot\\frac{1}{2}}{\\frac{3}{4}} = \\frac{4}{9}$\n",
    "\n",
    "- **[3]** (###) The inhabitants of an island tell the truth one third of the time. They lie with probability $2/3$. On an occasion, after one of them made a statement, you ask another \"was that statement true?\" and he says \"yes\". What is the probability that the statement was indeed true?\n",
    "> We use variables $S_1$ and $S_2$ for statements 1 and 2 and shorthand \"y\", \"n\", \"t\" and \"f\" for \"yes\", \"no\", \"true and \"false\", respectively. The problem statement provides us with the following probabilities,\n",
    "$$\\begin{align*}\n",
    "p(S_1=\\text{t})&= 1/3\\\\\n",
    "p(S_1=\\text{f})&= 1 - p(S_1=\\text{t})= 2/3\\\\\n",
    "p(S_2=\\text{y}|S_1=\\text{t})&= 1/3 \\\\\n",
    "p(S_2=\\text{y}|S_1=\\text{f})&= 1-p(S_2=\\text{y}|S_1=\\text{t})= 2/3\n",
    "\\end{align*}$$\n",
    "We are asked to compute $p(S_1=\\text{t}|S_2=\\text{y})$. Use Bayes rule,\n",
    "$$\\begin{align*}\n",
    "p(S_1=\\text{t}|S_2=\\text{y}) &= \\frac{p(S_1=\\text{t},S_2=\\text{y})}{p(S_2=\\text{y})}\\\\\n",
    "&=\\frac{p(S_2=\\text{y}|S_1=\\text{t})p(S_1=\\text{t})}{p(S_2=\\text{y}|S_1=\\text{t})p(S_1=\\text{t})+p(S_2=\\text{y}|S_1=\\text{f})p(S_1=\\text{f})}\\\\\n",
    "&= \\frac{\\frac{1}{3}\\cdot\\frac{1}{3}}{\\frac{1}{3}\\cdot\\frac{1}{3}+\\frac{2}{3}\\cdot\\frac{2}{3}} = \\frac{1}{5}\n",
    "\\end{align*}$$\n",
    "\n",
    "- **[4]** (##) A bag contains one ball, known to be either white or black. A white ball is put in, the bag is shaken, and a ball is drawn out, which proves to be white. What is now the chance of drawing a white ball? (Note that the state of the bag, after the operations, is exactly identical to its state before.)\n",
    "> There are two hypotheses: let $H = 0$ mean that the original ball in the bag was white and $H = 1$ that is was black.\n",
    "Assume the prior probabilities are equal. The data is that when a randomly selected ball was drawn from the bag, which contained a white one and the unknown one, it turned out to be white. The probability of this result according to each hypothesis is:\n",
    "$$ P(D|H =0) = 1,\\quad P(D|H =1) = 1/2$$\n",
    "So by Bayes theorem, the posterior probability of $H$ is\n",
    "$$P(H =0|D) = 2/3,\\quad P(H =1|D) = 1/3$$\n",
    "\n",
    "- **[5]**  A dark bag contains five red balls and seven green ones.      \n",
    "  (a) (#) What is the probability of drawing a red ball on the first draw?      \n",
    "  (b) (##) Balls are not returned to the bag after each draw. If you know that on the second draw the ball was a green one, what is now the probability of drawing a red ball on the first draw?       \n",
    "> (a) $p(S_1=R) = \\frac{N_R}{N_R+N_G}= \\frac{5}{12}$        \n",
    "> (b) The outcome of the $n$th draw is referred to by variable $S_n$. Use Bayes rule to get \n",
    "$$\\begin{align*}\n",
    "p(S_1=\\text{R}|S_2=\\text{G}) &=\\frac{p(S_2=\\text{G}|S_1=\\text{R})p(S_1=\\text{R})}{p(S_2=\\text{G}|S_1=\\text{R})p(S_1=\\text{R})+p(S_2=\\text{G}|S_1=\\text{G})p(S_1=\\text{G})}\\\\\n",
    "&= \\frac{\\frac{7}{11}\\cdot\\frac{5}{12}}{\\frac{7}{11}\\cdot\\frac{5}{12}+\\frac{6}{11}\\cdot\\frac{7}{12}} = \\frac{5}{11}\n",
    "\\end{align*}$$\n",
    "\n",
    "- **[6]**  (#) Is it more correct to speak about the likelihood of a _model_ (or model parameters) than about the likelihood of an _observed data set_. And why? \n",
    "\n",
    "- **[7]** (##) Is a speech signal a 'probabilistic' (random) or a deterministic signal?\n",
    "\n",
    "- **[8]** A dark bag contains five red balls and seven green ones.      \n",
    "  (a) (#) What is the probability of drawing a red ball on the first draw?       \n",
    "  (b) (##) Balls are not returned to the bag after each draw. If you know that on the second draw the ball was a green one, what is now the probability of drawing a red ball on the first draw?\n",
    "\n",
    "- **[9]** (##) A bag contains one ball, known to be either white or black. A white ball is put in, the bag is shaken, and a ball is drawn out, which proves to be white. What is now the chance of drawing a white ball?\n",
    " \n",
    "- **[10]** (##) Proof that, for any distribution of $x$ and $y$ and $z=x+y$\n",
    "$$\\begin{align*}\n",
    "    \\mathrm{E}[z] &= \\mathrm{E}[x] + \\mathrm{E}[y] \\\\\n",
    "    \\mathrm{var}[z] &= \\mathrm{var}[x] + \\mathrm{var}[y] + 2\\mathrm{cov}[x,y] \n",
    "\\end{align*}$$\n",
    "You may make use of the more general theorem that the mean and variance of any distribution $p(x)$ is processed by a linear tranformation as\n",
    " $$\\begin{align*}\n",
    "\\mathrm{E}[Ax +b] &= A\\mathrm{E}[x] + b \\\\\n",
    "\\mathrm{var}[Ax +b] &= A\\,\\mathrm{var}[x]\\,A^T \n",
    "\\end{align*}$$\n",
    "> Define $A = [1, 1]$, $w = [x;y]$ (where the notation \";\" stacks the columns of $x$ and $y$). Then $z = A w$. Now apply the formula for the mean and variance of a RV after a linear transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Machine Learning\n",
    "\n",
    "\n",
    "- **[1]** (#) (a) Explain shortly the relation between machine learning and Bayes rule.     \n",
    "   (b) How are Maximum a Posteriori (MAP) and Maximum Likelihood (ML) estimation related to Bayes rule and machine learning?\n",
    "> (a) Machine learning is inference over models (hypotheses, parameters, etc.) from a given data set. *Bayes rule* makes this statement precise. Let $\\theta \\in \\Theta$ and $D$ represent a model parameter vector and the given data set, respectively. Then, Bayes rule,\n",
    "$$\n",
    "p(\\theta|D) = \\frac{p(D|\\theta)}{p(D)} p(\\theta)\n",
    "$$\n",
    "relates the information that we have about $\\theta$ before we saw the data (i.e., the distribution $p(\\theta)$) to what we know after having seen the data, $p(\\theta|D)$.      \n",
    "> (b) The *Maximum a Posteriori* (MAP) estimate picks a value $\\hat\\theta$ for which the posterior distribution $p(\\theta|D)$ is maximal, i.e.,\n",
    "$$ \\hat\\theta_{MAP} = \\arg\\max_\\theta p(\\theta|D)$$\n",
    "In a sense, MAP estimation approximates Bayesian learning, since we approximated $p(\\theta|D)$ by $\\delta(\\theta-\\hat\\theta_{\\text{MAP}})$. Note that, by Bayes rule, $$\\arg\\max_\\theta p(\\theta|D) = \\arg\\max_\\theta p(D|\\theta)p(\\theta)$$\n",
    "If we further assume that prior to seeing the data all values for $\\theta$ are equally likely (i.e., $p(\\theta)=\\text{const.}$), then the MAP estimate reduces to the *Maximum Likelihood* estimate,\n",
    "$$ \\hat\\theta_{ML} = \\arg\\max_\\theta p(D|\\theta)$$\n",
    "\n",
    "- **[2]** (#) What are the four stages of the Bayesian design approach?\n",
    "\n",
    "- **[3]** (##) The Bayes estimate is a summary of a posterior distribution by a delta distribution on its mean, i.e., \n",
    "$$\n",
    "\\hat \\theta_{bayes}  = \\int \\theta \\, p\\left( \\theta |D \\right)\n",
    "\\,\\mathrm{d}{\\theta}\n",
    "$$\n",
    "Proof that the Bayes estimate minimizes the expected mean-square error, i.e., proof that\n",
    "$$\n",
    "\\hat \\theta_{bayes} = \\arg\\min_{\\hat \\theta} \\int_\\theta (\\hat \\theta -\\theta)^2 p \\left( \\theta |D \\right) \\,\\mathrm{d}{\\theta}\n",
    "$$\n",
    "\n",
    "- **[4]** (##) We make $N$ IID observations $D=\\{x_1 \\dots x_N\\}$ and assume the following model\n",
    "$$\n",
    "x_k = A + \\epsilon_k \n",
    "$$\n",
    "  where $\\epsilon_k = \\mathcal{N}(\\epsilon_k | 0,\\sigma^2)$ with known $\\sigma^2=1$. We are interested in deriving an estimator for $A$.   \n",
    "  (a) Make a reasonable assumption for a prior on $A$ and derive a Bayesian (posterior) estimate.     \n",
    "  (b) Derive the Maximum Likelihood estimate for $A$.     \n",
    "  (c) Derive the MAP estimates for $A$.    \n",
    "  (d) Now assume that we do not know the variance of the noise term? Describe the procedure for Bayesian estimation of both $A$ and $\\sigma^2$ (No need to fully work out to closed-form esitmates). \n",
    "   \n",
    "- **[5]** (##) We consider the coin toss example from the notebook and use a conjugate prior for a Bernoulli likelihood function.    \n",
    "  (a) Derive the Maximum Likelihood estimate.    \n",
    "  (b) Derive the MAP estimate.          \n",
    "  (c) Do these two estimates ever coincide (if so under what circumstances)?      \n",
    "\n",
    "- **[6]** (###) Given a single observation $x_0$ from a uniform distribution $\\mathrm{Unif}[0,1/\\theta]$, where $\\theta > 0$.  \n",
    "  (a) Show that $\\mathbb{E}[g(x_0)] = \\theta$  if and only if $\\int_0^{1/\\theta} g(u) du =1$.     \n",
    "  (b) Show that there is no function $g$ that satisfies the condition for all $\\theta > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Continuous Data and the Gaussian Distribution\n",
    "\n",
    "\n",
    "- **[1]** (##) We are given an IID data set $D = \\{x_1,x_2,\\ldots,x_N\\}$, where $x_n \\in \\mathbb{R}^M$. Let's assume that the data were drawn from a multivariate Gaussian (MVG),\n",
    "$$\\begin{align*}\n",
    "p(x_n|\\theta) = \\mathcal{N}(x_n|\\,\\mu,\\Sigma) = |2 \\pi \\Sigma|^{-\\frac{1}{2}} \\exp\\left\\{-\\frac{1}{2}(x_n-\\mu)^T\n",
    "\\Sigma^{-1} (x_n-\\mu) \\right\\}\n",
    "\\end{align*}$$      \n",
    "  (a) Derive the log-likelihood of the parameters for these data.       \n",
    "  (b) Derive the maximum likelihood estimates for the mean $\\mu$ and variance $\\Sigma$ by setting the derivative of the log-likelihood to zero.\n",
    "\n",
    "- **[2]** (#) Shortly explain why the Gaussian distribution is often preferred over other distributions with the same support?\n",
    "\n",
    "- **[3]** (###) Proof that the Gaussian distribution is the maximum entropy distribution over the reals with specified mean and variance.\n",
    "\n",
    "- **[4]** (##) Proof that a linear transformation $z=Ax+b$ of a Gaussian variable $\\mathcal{N}(x|\\mu,\\Sigma)$ is Gaussian distributed as\n",
    "$$\n",
    "p(z) = \\mathcal{N} \\left(z \\,|\\, A\\mu+b, A\\Sigma A^T \\right) \n",
    "$$\n",
    "\n",
    "- **[5]** (#) Given independent variables\n",
    "$x \\sim \\mathcal{N}(\\mu_x,\\sigma_y^2)$ and $y \\sim \\mathcal{N}(\\mu_y,\\sigma_y^2)$, what is the PDF for $z = A\\cdot(x -y) + b$?    \n",
    ">  $z$ is also Gaussian with \n",
    "$$\n",
    "p_z(z) = \\mathcal{N}(z \\,|\\, A(\\mu_x-\\mu_y)+b, \\, A (\\sigma_x^2 + \\sigma_y^2) A^T)\n",
    "$$\n",
    "\n",
    "\n",
    "- **[6]** (##) Compute\n",
    "\n",
    "\\begin{equation*}\n",
    "        \\int_{-\\infty}^{\\infty} \\exp(-x^2)\\mathrm{d}x \\,.\n",
    "    \\end{equation*}\n",
    "    \n",
    "\n",
    "<!---\n",
    "- Derive the conditional distribution $p(x_a|x_b)$ and the marginal distribution $p(x_a)$ given that \n",
    "$$\n",
    "\\begin{bmatrix} x_a \\\\ x_b \\end{bmatrix} \\sim \\mathcal{N}\\left(\\begin{bmatrix} m_a \\\\m_b \\end{bmatrix} , \\begin{bmatrix} \\Sigma_a ~ \\Sigma_{ab} \\\\ \\Sigma_{ba} ~  \\Sigma_b\\end{bmatrix}\\right),\n",
    "$$\n",
    "where $x_a$ and $x_b$ are vectors. You may make use of \n",
    "$$\n",
    "       \\begin{bmatrix} A ~ B \\\\ C ~ D \\end{bmatrix}^{-1} = \\begin{bmatrix} M \\qquad -MBD^{-1} \\\\ -D^{-1}CM \\qquad D^{-1}+D^{-1}CMBD^{-1} \\end{bmatrix}\n",
    "$$\n",
    "where $M = (A - BD^{-1}C)^{-1}$ is called the Schur's complement.\n",
    "\n",
    "    \n",
    "- In the notebook, for the model \n",
    "$$\\begin{align*}\n",
    "p(x_t |\\theta) &= \\mathcal{N}(x_t\\,|\\,\\theta,\\sigma^2) \\\\\n",
    "p(\\theta) &= \\mathcal{N}(\\theta\\,|\\,\\mu_0,\\sigma_0^2)\n",
    "\\end{align*}$$\n",
    "we found the following posteestimator for the hidden states:\n",
    "$$\\begin{align*}\n",
    "p(\\theta|x) &= \\mathcal{N} \\left( \\theta\\,|\\,\\mu_1, \\sigma_1^2 \\right)\\,,\n",
    "\\end{align*}$$\n",
    "with\n",
    "$$\\begin{align*}\n",
    "K &= \\frac{\\sigma_0^2}{\\sigma_0^2+\\sigma^2} \\qquad \\text{($K$ is called: Kalman gain)}\\\\\n",
    "\\mu_1 &= \\mu_0 + K \\cdot (x-\\mu_0)\\\\\n",
    "\\sigma_1^2 &= \\left( 1-K \\right) \\sigma_0^2  \n",
    "\\end{align*}$$\n",
    " \n",
    "\n",
    "\n",
    "- Show that Eq.SRG-8 is a special case of Eq.SRG-4a. \n",
    "\n",
    "- Proof\n",
    "$$\n",
    "p(x,\\theta) = \\mathcal{N} \\left( \\begin{bmatrix} x\\\\ \n",
    "  \\theta  \\end{bmatrix} \n",
    "  \\,\\left|\\, \\begin{bmatrix} \\mu_0\\\\ \n",
    "  \\mu_0\\end{bmatrix}, \n",
    "         \\begin{bmatrix} \\sigma_0^2+\\sigma^2  & \\sigma_0^2\\\\ \n",
    "         \\sigma_0^2 &\\sigma_0^2 \n",
    "  \\end{bmatrix} \n",
    "  \\right. \\right)\n",
    "$$\n",
    "- Look up conditioning and marginalization in canonical coordinates and compare to the formulas for the moment parameterization of the Gaussian. Any conclusions?\n",
    "--->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discrete Data and the Multinomial Distribution\n",
    "\n",
    "- **[1]** (##) We consider IID data $D = \\{x_1,x_2,\\ldots,x_N\\}$ obtained from tossing a $K$-sided die. We use a *binary selection variable*\n",
    "$$x_{nk} \\equiv \\begin{cases} 1 & \\text{if $x_n$ lands on $k$th face}\\\\\n",
    "    0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "with probabilities $p(x_{nk} = 1)=\\theta_k$.      \n",
    "  (a) Write down the probability for the $n$th observation $p(x_n|\\theta)$ and derive the log-likelihood $\\log p(D|\\theta)$.     \n",
    "  (b) Derive the maximum likelihood estimate for $\\theta$.\n",
    "> See lecture notes (on class homepage).      \n",
    "  (a) $p(x_n|\\theta) = \\prod_k \\theta_k^{x_{nk}} \\quad \\text{subject to} \\quad \\sum_k \\theta_k = 1$.\n",
    "$$\\ell(\\theta)  = \\sum_k m_k \\log \\theta_k$$\n",
    "where $m_k = \\sum_k x_{nk}$.     \n",
    "  (b) $\\hat \\theta = \\frac{m_k}{N}$, the *sample proportion*.\n",
    "\n",
    "- **[2]** (#) In the notebook, Laplace's generalized rule of succession (the probability that we throw the $k$th face at the next toss) was derived as \n",
    "$$\\begin{align*}\n",
    "p(x_{\\bullet,k}=1|D) = \\frac{m_k + \\alpha_k }{ N+ \\sum_k \\alpha_k}\n",
    "\\end{align*}$$\n",
    "Provide an interpretation of the variables $m_k,N,\\alpha_k,\\sum_k$ and $\\alpha_k$.\n",
    "\n",
    "- **[3]** (##) Show that Laplace's generalized rule of succession can be worked out to a prediction that is composed of a prior prediction and data-based correction term. \n",
    "\n",
    "- **[4]** (#) Verify that\n",
    "  - the categorial distribution is a special case of the multinomial for $N=1$. \n",
    "  - the Bernoulli is a special case of the categorial distribution for $K=2$.\n",
    "  - the binomial is a special case of the multinomial for $K=2$.\n",
    "\n",
    "- **[5]** (###) Determine the mean, variance and mode of a Beta distribution.\n",
    "\n",
    "- **[6]** (###) Consider a data set of binary variables $D=\\{x_1,x_2,\\ldots,x_N\\}$ with a Bernoulli distribution $\\mathrm{Ber}(x_k|\\mu)$ as data generating distribution and a Beta prior for $\\mu$. Assume that you make $n$ observations with $x=1$ and $N-n$ observations with $x=0$. Now consider a new draw $x_\\bullet$. We are interested in computing $p(x_\\bullet|D)$. Show that the mean value for $p(x_\\bullet|D)$ lies in between the prior mean and Maximum Likelihood estimate.\n",
    "\n",
    "<!---\n",
    "- Show that the beta, categorical, multinomial and Dirichlet distributions are normalized.\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression\n",
    "\n",
    "\n",
    "- **[1]** (#) (a) Write down the generative model for Bayesian linear ordinary regression (i.e., write the likelihood and prior).     \n",
    "   (b) State the inference task for the weight parameter in the model.    \n",
    "   (c) Why do we call this problem linear?\n",
    "\n",
    "- **[2]** (##) Consider a linear regression problem with $y, X$ and $w$ as defined in the notebook.     \n",
    "  (a) Work out the maximum likelihood solution for linear regression by solving\n",
    "  \n",
    "$$\n",
    "\\nabla_{w} \\log p(y|X,w) = 0 \\,.\n",
    "$$    \n",
    "  \n",
    "    \n",
    "  (b) Work out the Bayesian solution. How does it relate to the ML solution?\n",
    "\n",
    "- **[3]** (###) Show that the variance of the predictive distribution for linear regression decreases as more data becomes available.\n",
    "\n",
    "<!---\n",
    "- Let's work out the log-likelihood for multiple observations\n",
    "$$\\begin{align*}\n",
    "\\log p(D|w) &\\stackrel{\\text{IID}}{=} \\sum_n \\log \\mathcal{N}(y_n|\\,w^T x_n,\\sigma^2) \\propto -\\frac{1}{2\\sigma^2} \\sum_{n} {(y_n - w^T x_n)^2}\\\\\n",
    "    &= -\\frac{1}{2\\sigma^2}\\left( {y - \\mathbf{X}w } \\right)^T \\left( {y - \\mathbf{X} w } \\right)\n",
    "\\end{align*}$$\n",
    "where  we defined $N\\times 1$ vector $y  = \\left(y_1 ,y_2 , \\ldots ,y_N \\right)^T$ and $(N\\times D)$-dim matrix $\\mathbf{X}  = \\left( x_1 ,x_2 , \\ldots ,x_n \\right)^T$.\n",
    "\n",
    "\n",
    "- - Now, we want to apply the trained model. New data points can be predicted by\n",
    "$$\\begin{equation*}\n",
    "p(y_\\bullet \\,|\\, x_\\bullet,\\hat w_{\\text{ML}}) = \\mathcal{N}(y_\\bullet \\,|\\, \\hat w_{\\text{ML}}^T x_\\bullet, \\sigma^2 ) \n",
    "\\end{equation*}$$\n",
    "\n",
    "- Note that the expected value of a predicted new data point\n",
    "\n",
    "$$\n",
    "\\mathrm{E}[y_\\bullet] = \\hat w_{\\text{ML}}^T x_\\bullet = x_\\bullet^T \\hat{w}_{\\text{ML}} = \\left( x_\\bullet^T \\mathbf{X}^\\dagger \\right) y\n",
    "$$\n",
    "\n",
    "can also be expressed as a linear combination of the observed data points \n",
    "\n",
    "$$y  = \\left( {y_1 ,y_1 , \\ldots ,y_N } \\right)^T \\,.$$\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generative Classification\n",
    "\n",
    "- **[1]** You have a machine that measures property $x$, the \"orangeness\" of liquids. You wish to discriminate between $C_1 = \\text{`Fanta'}$ and $C_2 = \\text{`Orangina'}$. It is known that\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(x|C_1) &= \\begin{cases} 10 & 1.0 \\leq x \\leq 1.1\\\\\n",
    "    0 & \\text{otherwise}\n",
    "    \\end{cases}\\\\\n",
    "p(x|C_2) &= \\begin{cases} 200(x - 1) & 1.0 \\leq x \\leq 1.1\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{align*}$$\n",
    "\n",
    "The prior probabilities $p(C_1) = 0.6$ and $p(C_2) = 0.4$ are also known from experience.       \n",
    "  (a) (##) A \"Bayes Classifier\" is given by\n",
    "  \n",
    "$$ \\text{Decision} = \\begin{cases} C_1 & \\text{if } p(C_1|x)>p(C_2|x) \\\\\n",
    "                               C_2 & \\text{otherwise}\n",
    "                 \\end{cases}\n",
    "$$\n",
    "\n",
    "Calculate the optimal Bayes classifier.      \n",
    "  (b) (###) The probability of making the wrong decision, given $x$, is\n",
    "  \n",
    "$$\n",
    "p(\\text{error}|x)= \\begin{cases} p(C_1|x) & \\text{if we decide $C_2$}\\\\\n",
    "    p(C_2|x) & \\text{if we decide $C_1$}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Compute the **total** error probability  $p(\\text{error})$ for the Bayes classifier in this example.\n",
    "\n",
    "> (a) We choose $C_1$ if $p(C_1|x)/p(C_2|x) > 1$. This condition can be worked out as\n",
    "$$\n",
    "\\frac{p(C_1|x)}{p(C_2|x)} = \\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)} = \\frac{10 \\times 0.6}{200(x-1)\\times 0.4}>1\n",
    "$$\n",
    "which evaluates to choosing\n",
    "$$\\begin{align*}\n",
    "C_1 &\\quad \\text{ if $1.0\\leq x < 1.075$}\\\\ \n",
    "C_2 &\\quad \\text{ if $1.075 \\leq x \\leq 1.1$ }\n",
    "\\end{align*}$$\n",
    "The probability that $x$ falls outside the interval $[1.0,1.1]$ is zero.       \n",
    "> (b) The total probability of error $p(\\text{error})=\\int_x p(\\text{error}|x)p(x) \\mathrm{d}{x}$. We can work this out as\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(\\text{error}) &= \\int_x p(\\text{error}|x)p(x)\\mathrm{d}{x}\\\\\n",
    "&= \\int_{1.0}^{1.075} p(C_2|x)p(x) \\mathrm{d}{x} + \\int_{1.075}^{1.1} p(C_1|x)p(x) \\mathrm{d}{x}\\\\\n",
    "&= \\int_{1.0}^{1.075} p(x|C_2)p(C_2) \\mathrm{d}{x} + \\int_{1.075}^{1.1} p(x|C_1)p(C_1) \\mathrm{d}{x}\\\\\n",
    "&= \\int_{1.0}^{1.075}0.4\\cdot 200(x-1) \\mathrm{d}{x} + \\int_{1.075}^{1.1} 0.6\\cdot 10 \\mathrm{d}{x}\\\\\n",
    "&=80\\cdot[x^2/2-x]_{1.0}^{1.075} + 6\\cdot[x]_{1.075}^{1.1}\\\\\n",
    "&=0.225 + 0.15\\\\\n",
    "&=0.375\n",
    "\\end{align*}$$\n",
    "\n",
    "- **[2]** Consider a given data set $D=\\{(x_1,y_1),\\ldots,(x_N,y_N)\\}$ where $x_n \\in \\mathbb{R}^M$ are input features and $y_n \\in \\{0,1\\}$ are given class labels.    \n",
    "  (a) (#) Write down the generative model for this classification task using a Gaussian likelihood with Bernoulli priors for class labels.  \n",
    "  (b) How do you compute the posterior distribution for class labels, given a new input $x_\\bullet$, ie, how do you compute $p(y_\\bullet|x_\\bullet,D)$?      \n",
    "  (c) (##) Work out the likelihood function for the parameters.     \n",
    "  (d) (###) Derive the Maximum Likelihood estimates for the parameters by the gradient of the likelihood to zero.\n",
    "  \n",
    "- **[3]** Refer to [Bishop's PRML book](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf) for the following exercises. Chapter 4: 4.8, 4.9, 4.10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discriminative Classification\n",
    "\n",
    "- **[1]**  Given a data set $D=\\{(x_1,y_1),\\ldots,(x_N,y_N)\\}$, where $x_n \\in \\mathbb{R}^M$ and $y_n \\in \\{0,1\\}$. The probabilistic classification method known as *logistic regression* attempts to model these data as\n",
    "$$p(y_n=1|x_n) = \\sigma(\\theta^T x_n + b)$$\n",
    "where $\\sigma(x) = 1/(1+e^{-x})$ is the *logistic function*. Let's introduce shorthand notation $\\mu_n=\\sigma(\\theta^T x_n + b)$. So, for every input $x_n$, we have a model output $\\mu_n$ and an actual data output $y_n$.                   \n",
    "  (a) Express $p(y_n|x_n)$ as a Bernoulli distribution in terms of $\\mu_n$ and $y_n$.         \n",
    "  (b) If furthermore is given that the data set is IID, show that the log-likelihood is given by\n",
    "  \n",
    "$$\n",
    "L(\\theta) \\triangleq \\log p(D|\\theta) = \\sum_n \\left\\{y_n \\log \\mu_n  + (1-y_n)\\log(1-\\mu_n)\\right\\}\n",
    "$$     \n",
    "\n",
    "  (c) Prove that the derivative of the logistic function is given by\n",
    "  \n",
    "$$\n",
    "\\sigma^\\prime(\\xi) = \\sigma(\\xi)\\cdot\\left(1-\\sigma(\\xi)\\right)\n",
    "$$  \n",
    "\n",
    "  (d) Show that the derivative of the log-likelihood is\n",
    "  \n",
    "$$\n",
    "\\nabla_\\theta L(\\theta) = \\sum_{n=1}^N \\left( y_n - \\sigma(\\theta^T x_n +b)\\right)x_n\n",
    "$$\n",
    "\n",
    "  (e) Design a gradient-ascent algorithm for maximizing $L(\\theta)$ with respect to $\\theta$.     \n",
    "  (f) Interpret this result.\n",
    "\n",
    "- **[2]** Describe shortly in your own words the similarities and differences between the discriminative and generative approach to classification.\n",
    "\n",
    "- **[3]** Refer to [Bishop's PRML book](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf) for the following exercises. Chapter 4:  4.7, 4.12, 4.16, 4.22. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Latent Variable Models and Variational Bayes\n",
    "\n",
    "- **[1]** For a Gaussian mixture model, given by generative equations\n",
    "\n",
    "$$\n",
    "p(x_n,z_n) = \\prod_{k=1}^K (\\underbrace{\\pi_k \\cdot \\mathcal{N}\\left( x_n | \\mu_k, \\Sigma_k\\right) }_{p(x_n,z_{nk}=1)})^{z_{nk}} \n",
    "$$\n",
    "\n",
    "proof that the marginal distribution for observations $x_n$ evaluates to \n",
    "\n",
    "$$\n",
    "p(x_n) = \\sum_{k=1}^K \\pi_k \\cdot \\mathcal{N}\\left( x_n | \\mu_k, \\Sigma_k \\right) \n",
    "$$\n",
    "\n",
    "- **[2]**  Given the free energy functional $\n",
    "F[q] = \\sum_z q(z) \\log \\frac{q(z)}{p(x,z)}$, proof the [EE, DE and AC decompositions](https://nbviewer.jupyter.org/github/bertdv/BMLIP/blob/master/lessons/notebooks/09-Latent-Variable-Models-and-VB.ipynb#fe-decompositions). \n",
    "\n",
    "- **[3]** Figure out (eg consult the internet) why the first term in the DE decomposition \n",
    "\n",
    "$$\n",
    "\\mathrm{F}[q] = \\underbrace{-\\sum_z q(z) \\log p(x,z)}_{\\text{energy}} - \\underbrace{\\sum_z q(z) \\log \\frac{1}{q(z)}}_{\\text{entropy}}\n",
    "$$\n",
    "\n",
    "is called an \"energy\" term. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dynamic Models \n",
    "\n",
    "- **[1]** Given the Markov property\n",
    "\\begin{equation*}\n",
    "p(x_n|x_{n-1},x_{n-2},\\ldots,x_1) = p(x_n|x_{n-1}) \\tag{A1}\n",
    "\\end{equation*}\n",
    "proof that, for any $n$,\n",
    "\\begin{align*}\n",
    "p(x_n,x_{n-1},&\\ldots,x_{k+1},x_{k-1},\\ldots,x_1|x_k) = \\\\\n",
    "&p(x_n,x_{n-1},\\ldots,x_{k+1}|x_k) \\cdot p(x_{k-1},x_{k-2},\\ldots,x_1|x_k) \\tag{A2}\\,.\n",
    "\\end{align*}\n",
    "In other words, proof that, if the Markov property A1 holds, then, given the \"present\" ($x_k$), the \"future\" $(x_n,x_{n-1},\\ldots,x_{k+1})$ is _independent_ of the \"past\" $(x_{k-1},x_{k-2},\\ldots,x_1)$.\n",
    ">  First, we rewrite A2 as\n",
    "\\begin{align*}\n",
    "p(&x_n,x_{n-1},\\ldots,x_{k+1},x_{k-1},\\ldots,x_1|x_k) = \\frac{p(x_n,x_{n-1},\\ldots,x_1)}{p(x_k)} \\\\\n",
    "&= \\frac{p(x_n,x_{n-1},\\ldots,x_{k+1}|x_k,\\ldots,x_1) \\cdot p(x_k,x_{k-1},\\ldots,x_1)}{p(x_k)} \\\\\n",
    "&= p(x_n,x_{n-1},\\ldots,x_{k+1}|x_k,\\ldots,x_1) \\cdot p(x_{k-1},\\ldots,x_1|x_k) \\tag{A3}\n",
    "\\end{align*}\n",
    "The first term in A3 can be simplified if A1 holds to \n",
    "\\begin{align*}\n",
    "p(x_n,&x_{n-1},\\ldots,x_{k+1}|x_k,x_{k-1},\\ldots,x_1) \\\\\n",
    "&= p(x_n|x_{n-1},x_{n-2},\\ldots,x_1) \\cdot p(x_{n-1}|x_{n-2},x_{n-3},\\ldots,x_1) \\cdots \\\\\n",
    "&\\quad \\cdots p(x_{k+1}|x_{k},x_{k-2},\\ldots,x_1) \\\\\n",
    "&= p(x_n|x_{n-1},x_{n-2},\\ldots,x_k) \\cdot p(x_{n-1}|x_{n-2},x_{n-3},\\ldots,x_k) \\cdots \\\\\n",
    "&\\quad \\cdots p(x_{k+1}|x_{k}) \\\\\n",
    "&= p(x_n,x_{n-1},\\ldots,x_{k+1}|x_k) \\tag{A4}\n",
    "\\end{align*}\n",
    "Substitution of A4 into A3 leads to A2. QED.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discriminative Classification\n",
    "\n",
    "1.  Given a data set $D=\\{(x_1,y_1),\\ldots,(x_N,y_N)\\}$, where $x_n \\in \\mathbb{R}^M$ and $y_n \\in \\{0,1\\}$. The probabilistic classification method known as *logistic regression* attempts to model these data as\n",
    "$$p(y_n=1|x_n) = \\sigma(\\theta^T x_n + b)$$\n",
    "where $\\sigma(x) = 1/(1+e^{-x})$ is the *logistic function*. Let's introduce shorthand notation $\\mu_n=\\sigma(\\theta^T x_n + b)$. So, for every input $x_n$, we have a model output $\\mu_n$ and an actual data output $y_n$.                   \n",
    "  (a) Express $p(y_n|x_n)$ as a Bernoulli distribution in terms of $\\mu_n$ and $y_n$.         \n",
    "  (b) If furthermore is given that the data set is IID, show that the log-likelihood is given by\n",
    "$$\n",
    "L(\\theta) \\triangleq \\log p(D|\\theta) = \\sum_n \\left\\{y_n \\log \\mu_n  + (1-y_n)\\log(1-\\mu_n)\\right\\}\n",
    "$$        \n",
    "  (c) Prove that the derivative of the logistic function is given by\n",
    "$$\n",
    "\\sigma^\\prime(\\xi) = \\sigma(\\xi)\\cdot\\left(1-\\sigma(\\xi)\\right)\n",
    "$$              \n",
    "  (d) Show that the derivative of the log-likelihood is\n",
    "$$\n",
    "\\nabla_\\theta L(\\theta) = \\sum_{n=1}^N \\left( y_n - \\sigma(\\theta^T x_n +b)\\right)x_n\n",
    "$$               \n",
    "  (e) Design a gradient-ascent algorithm for maximizing $L(\\theta)$ with respect to $\\theta$.     \n",
    "  (f) Interpret this result.\n",
    ">  (a) $p(y_n|x_n) = p(y_n=1|x_n)^{y_n} p(y_n=0|x_n)^{1-y_n} = \\mu_n^{y_n}(1-\\mu_n)^{1-y_n}$               \n",
    ">  (b) The log-likelihood is given by\n",
    "$$\\begin{align*} L(\\theta) &= \\log p(D|\\theta) = \\sum_n \\log p(y_n|x_n,\\theta)\\\\\n",
    "&= \\sum_n \\left\\{y_n \\log \\mu + (1-y_n)\\log(1-\\mu_n)\\right\\}\n",
    "\\end{align*}$$               \n",
    ">  (c) $$\\begin{align*}\n",
    "\\frac{d{}}{d{\\xi}}\\left( \\frac{1}{1+e^{-\\xi}}\\right) &= \\frac{(1+e^{-\\xi})\\cdot 0 - (-e^{-\\xi}\\cdot 1)}{(1+e^{-\\xi})^2}\\\\\n",
    "&= \\frac{e^{-\\xi}}{(1+e^{-\\xi})^2} = \\frac{1}{1+e^{-\\xi}}\\cdot \\frac{e^{-\\xi}}{1+e^{-\\xi}}\\\\\n",
    "&=\\sigma(\\xi)\\left( 1-\\sigma(\\xi)\\right)\n",
    "\\end{align*}$$              \n",
    ">  (d)\n",
    "$$\\begin{align*}\n",
    "\\nabla_\\theta L(\\theta) &= \\sum_n \\left(\\frac{y_n}{\\mu_n} - \\frac{1-y_n}{1-\\mu_n} \\right) \\cdot \\frac{\\partial{\\mu_n}}{\\partial{(\\theta^T x_n +b)}} \\cdot \\frac{\\partial{(\\theta^T x_n +b)}}{\\partial{\\theta}}\\\\\n",
    "&= \\sum_n \\frac{y_n - \\mu_n}{\\mu_n(1-\\mu_n)} \\cdot \\mu_n(1-\\mu_n) \\cdot x_n\\\\\n",
    "&= \\sum_n (y_n - \\mu_n) \\cdot x_n\n",
    "\\end{align*}$$              \n",
    ">  (e)\n",
    "$$ \\theta^{(t+1)} = \\theta^{(t)} + \\rho \\sum_n (y_n - \\mu_n^{(t)})x_n$$\n",
    "\n",
    "2. Describe shortly in your own words the similarities and differences between the discriminative and generative approach to classification.\n",
    "\n",
    "3. Refer to [Bishop's PRML book](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf) for the following exercises. Chapter 4:  4.7, 4.12, 4.16, 4.22. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--\r\n",
       "This HTML file contains custom styles and some javascript.\r\n",
       "Include it a Jupyter notebook for improved rendering.\r\n",
       "-->\r\n",
       "\r\n",
       "<!-- Fonts -->\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Nixie+One' rel='stylesheet' type='text/css'>\r\n",
       "\r\n",
       "<!-- Custom style -->\r\n",
       "<style>\r\n",
       "\r\n",
       "@font-face {\r\n",
       "    font-family: \"Computer Modern\";\r\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\r\n",
       "}\r\n",
       "\r\n",
       "#notebook_panel { /* main background */\r\n",
       "    background: rgb(245,245,245);\r\n",
       "}\r\n",
       "\r\n",
       "div.container {\r\n",
       "    min-width: 960px;\r\n",
       "}\r\n",
       "\r\n",
       "div #notebook { /* centre the content */\r\n",
       "    background: #fff; /* white background for content */\r\n",
       "    margin: auto;\r\n",
       "    padding-left: 0em;\r\n",
       "}\r\n",
       "\r\n",
       "#notebook li { /* More space between bullet points */\r\n",
       "    margin-top:0.8em;\r\n",
       "}\r\n",
       "\r\n",
       "/* draw border around running cells */\r\n",
       "div.cell.border-box-sizing.code_cell.running {\r\n",
       "    border: 1px solid #111;\r\n",
       "}\r\n",
       "\r\n",
       "/* Put a solid color box around each cell and its output, visually linking them*/\r\n",
       "div.cell.code_cell {\r\n",
       "    background-color: rgb(256,256,256);\r\n",
       "    border-radius: 0px;\r\n",
       "    padding: 0.5em;\r\n",
       "    margin-left:1em;\r\n",
       "    margin-top: 1em;\r\n",
       "}\r\n",
       "\r\n",
       "div.text_cell_render{\r\n",
       "    font-family: 'Alegreya Sans' sans-serif;\r\n",
       "    line-height: 140%;\r\n",
       "    font-size: 125%;\r\n",
       "    font-weight: 400;\r\n",
       "    width:800px;\r\n",
       "    margin-left:auto;\r\n",
       "    margin-right:auto;\r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "/* Formatting for header cells */\r\n",
       ".text_cell_render h1 {\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    font-style:regular;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 45pt;\r\n",
       "    line-height: 100%;\r\n",
       "    color: rgb(0,51,102);\r\n",
       "    margin-bottom: 0.5em;\r\n",
       "    margin-top: 0.5em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h2 {\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 30pt;\r\n",
       "    line-height: 100%;\r\n",
       "    color: rgb(0,51,102);\r\n",
       "    margin-bottom: 0.1em;\r\n",
       "    margin-top: 0.3em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h3 {\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    margin-top:16px;\r\n",
       "    font-size: 22pt;\r\n",
       "    font-weight: 600;\r\n",
       "    margin-bottom: 3px;\r\n",
       "    font-style: regular;\r\n",
       "    color: rgb(102,102,0);\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h4 {    /*Use this for captions*/\r\n",
       "    font-family: 'Nixie One', serif;\r\n",
       "    font-size: 14pt;\r\n",
       "    text-align: center;\r\n",
       "    margin-top: 0em;\r\n",
       "    margin-bottom: 2em;\r\n",
       "    font-style: regular;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h5 {  /*Use this for small titles*/\r\n",
       "    font-family: 'Nixie One', sans-serif;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 16pt;\r\n",
       "    color: rgb(163,0,0);\r\n",
       "    font-style: italic;\r\n",
       "    margin-bottom: .1em;\r\n",
       "    margin-top: 0.8em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h6 { /*use this for copyright note*/\r\n",
       "    font-family: 'PT Mono', sans-serif;\r\n",
       "    font-weight: 300;\r\n",
       "    font-size: 9pt;\r\n",
       "    line-height: 100%;\r\n",
       "    color: grey;\r\n",
       "    margin-bottom: 1px;\r\n",
       "    margin-top: 1px;\r\n",
       "}\r\n",
       "\r\n",
       ".CodeMirror{\r\n",
       "    font-family: \"PT Mono\";\r\n",
       "    font-size: 90%;\r\n",
       "}\r\n",
       "\r\n",
       ".boxed { /* draw a border around a piece of text */\r\n",
       "  border: 1px solid blue ;\r\n",
       "}\r\n",
       "\r\n",
       "h4#CODE-EXAMPLE,\r\n",
       "h4#END-OF-CODE-EXAMPLE {\r\n",
       "    margin: 10px 0;\r\n",
       "    padding: 10px;\r\n",
       "    background-color: #d0f9ca !important;\r\n",
       "    border-top: #849f81 1px solid;\r\n",
       "    border-bottom: #849f81 1px solid;\r\n",
       "}\r\n",
       "\r\n",
       ".emphasis {\r\n",
       "    color: red;\r\n",
       "}\r\n",
       "\r\n",
       ".exercise {\r\n",
       "    color: green;\r\n",
       "}\r\n",
       "\r\n",
       ".proof {\r\n",
       "    color: blue;\r\n",
       "}\r\n",
       "\r\n",
       "code {\r\n",
       "  padding: 2px 4px !important;\r\n",
       "  font-size: 90% !important;\r\n",
       "  color: #222 !important;\r\n",
       "  background-color: #efefef !important;\r\n",
       "  border-radius: 2px !important;\r\n",
       "}\r\n",
       "\r\n",
       "/* This removes the actual style cells from the notebooks, but no in print mode\r\n",
       "   as they will be removed through some other method */\r\n",
       "@media not print {\r\n",
       "  .cell:nth-last-child(-n+2) {\r\n",
       "    display: none;\r\n",
       "  }\r\n",
       "}\r\n",
       "\r\n",
       "footer.hidden-print {\r\n",
       "    display: none !important;\r\n",
       "}\r\n",
       "    \r\n",
       "</style>\r\n",
       "\r\n",
       "<!-- MathJax styling -->\r\n",
       "<script>\r\n",
       "    MathJax.Hub.Config({\r\n",
       "                        TeX: {\r\n",
       "                           extensions: [\"AMSmath.js\"],\r\n",
       "                           equationNumbers: { autoNumber: \"AMS\", useLabelIds: true}\r\n",
       "                           },\r\n",
       "                tex2jax: {\r\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\r\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\r\n",
       "                },\r\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\r\n",
       "                \"HTML-CSS\": {\r\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\r\n",
       "                }\r\n",
       "        });\r\n",
       "</script>\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open(\"../../styles/aipstyle.html\") do f\n",
    "    display(\"text/html\", read(f,String))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
